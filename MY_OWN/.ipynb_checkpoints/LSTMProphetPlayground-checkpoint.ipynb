{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import talib\n",
    "from talib import abstract\n",
    "# Cointegration and Statistics\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Machine Learning\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "# Reporting visualization\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-18</th>\n",
       "      <td>579.049988</td>\n",
       "      <td>585.950012</td>\n",
       "      <td>558.500000</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>352723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-19</th>\n",
       "      <td>564.000000</td>\n",
       "      <td>573.599976</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>569.099976</td>\n",
       "      <td>392079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20</th>\n",
       "      <td>571.700012</td>\n",
       "      <td>571.700012</td>\n",
       "      <td>559.299988</td>\n",
       "      <td>565.500000</td>\n",
       "      <td>179633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-21</th>\n",
       "      <td>564.799988</td>\n",
       "      <td>565.250000</td>\n",
       "      <td>555.150024</td>\n",
       "      <td>561.349976</td>\n",
       "      <td>150571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-24</th>\n",
       "      <td>563.049988</td>\n",
       "      <td>563.700012</td>\n",
       "      <td>554.000000</td>\n",
       "      <td>556.650024</td>\n",
       "      <td>85179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close  Volume\n",
       "Date                                                              \n",
       "2023-07-18  579.049988  585.950012  558.500000  562.000000  352723\n",
       "2023-07-19  564.000000  573.599976  553.000000  569.099976  392079\n",
       "2023-07-20  571.700012  571.700012  559.299988  565.500000  179633\n",
       "2023-07-21  564.799988  565.250000  555.150024  561.349976  150571\n",
       "2023-07-24  563.049988  563.700012  554.000000  556.650024   85179"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the datast\n",
    "#[OLECTRA,\"LT\",\"CONCOR\",\"ELGIEQUIP\",\"IOC\",\"BEL\",\"TATAELXSI\",\"^NSEI\"]\n",
    "stock_name = \"ELGIEQUIP\"\n",
    "data = yfinance.download(tickers = \"{}.NS\".format(stock_name),start=\"2000-03-06\",\n",
    "                               interval = \"1d\", group_by = 'ticker', auto_adjust = True)\n",
    "\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RKxpqoBOSBX"
   },
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {'High': 'high', 'Low': 'low',\"Close\":\"close\",\"Open\": \"open\"}\n",
    "data.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indicators = talib.get_function_groups()[\"Pattern Recognition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(0,len(data)):\n",
    "    if i > 1:\n",
    "        tempData = {}\n",
    "        last_day = data.iloc[i-1]\n",
    "        #print((last_day['High'] + last_day['Low'] + last_day['Close'])/3)\n",
    "        tempData['Pivot'] = (last_day['high'] + last_day['low'] + last_day['close'])/3\n",
    "        tempData['R1'] = 2 * tempData['Pivot'] - last_day['low']\n",
    "        tempData['S1'] = 2 * tempData['Pivot'] - last_day['high']\n",
    "        tempData['R2'] = tempData['Pivot'] + (last_day['high'] - last_day['low'])\n",
    "        tempData['S2'] = tempData['Pivot'] - (last_day['high'] - last_day['low'])\n",
    "        tempData['R3'] = tempData['Pivot'] + 2*(last_day['high'] - last_day['low'])\n",
    "        tempData['S3'] = tempData['Pivot'] - 2*(last_day['high'] - last_day['low'])\n",
    "        tempData['low'] = last_day['low']\n",
    "        tempData['high'] = last_day['high']\n",
    "        tempData['close'] = last_day['close']\n",
    "        tempData['open'] = last_day['open']\n",
    "        tempData['Date'] = last_day.index\n",
    "        result.append(tempData)\n",
    "        \n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indicator in all_indicators:\n",
    "    if indicator == \"CDLHAMMER\" or indicator == \"CDLSHOOTINGSTAR\":\n",
    "        df[str(indicator)] = getattr(abstract, indicator)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['close',\"CDLSHOOTINGSTAR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "front_limit = 2\n",
    "backlimit = 5\n",
    "for i in range(backlimit,len(df)):\n",
    "    if i < len(df)- 2:\n",
    "        if df.iloc[i].CDLSHOOTINGSTAR != 0:\n",
    "           # print(i)\n",
    "            temp_data = df.iloc[(i-backlimit):(i + front_limit-1),]\n",
    "            #print(temp_data)\n",
    "            temp_data.reset_index(inplace=True)\n",
    "            temp_data = temp_data.drop(\"index\",axis=1)\n",
    "            temp_data = temp_data.drop(\"CDLSHOOTINGSTAR\",axis=1)\n",
    "\n",
    "            tempR = 0\n",
    "            for r in range(0,len(temp_data)):\n",
    "                tempR = tempR + temp_data.iloc[r].close\n",
    "\n",
    "            trend = (tempR / len(temp_data)) > temp_data.iloc[(len(temp_data)-1)-front_limit].close\n",
    "            y.append(temp_data.iloc[len(temp_data)-1].close)\n",
    "            #if trend == True:\n",
    "               # temp_data[\"isUptrend\"] = 1\n",
    "               \n",
    "              \n",
    "            #else:\n",
    "                #temp_data[\"isUptrend\"] = 0\n",
    "               \n",
    "            X.append(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 6, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X =X.reshape(X.shape[0],X.shape[1] , 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_3d_data(data):\n",
    "    #print(data.shape)\n",
    "    n, length, width, height = data.shape\n",
    "    return data.reshape(n, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 6, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_flattened \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_3d_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m, in \u001b[0;36mflatten_3d_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten_3d_data\u001b[39m(data):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     n, length, width, height \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "X_flattened = flatten_3d_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_flattened' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_flattened\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_flattened' is not defined"
     ]
    }
   ],
   "source": [
    "X_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_3d_data(data):\n",
    "    n, length, width, height = data.shape\n",
    "    return data.reshape(n, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(6,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 6, 50)             10400     \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 6, 50)             20200     \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50851 (198.64 KB)\n",
      "Trainable params: 50851 (198.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 20496.5840 - val_loss: 20483.6055\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 20476.0469 - val_loss: 20463.2832\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20456.2715 - val_loss: 20444.9609\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20438.3164 - val_loss: 20426.7930\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 20420.5059 - val_loss: 20408.8457\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20404.0000 - val_loss: 20391.1250\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 20386.9023 - val_loss: 20374.3105\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 20369.8496 - val_loss: 20358.0840\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 20351.9512 - val_loss: 20342.2207\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 20336.1777 - val_loss: 20325.5430\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20318.6133 - val_loss: 20308.7930\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 20304.9512 - val_loss: 20291.2656\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 20285.0605 - val_loss: 20275.3574\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 20269.3496 - val_loss: 20258.7500\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 20251.9199 - val_loss: 20242.3301\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 20238.3672 - val_loss: 20224.7852\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20218.9297 - val_loss: 20208.7227\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 20203.8887 - val_loss: 20191.9609\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 20185.9199 - val_loss: 20175.9180\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20170.6348 - val_loss: 20159.3555\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20155.3887 - val_loss: 20142.5020\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20136.5820 - val_loss: 20126.7402\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20123.1270 - val_loss: 20110.1992\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 20105.7402 - val_loss: 20093.8965\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20087.6270 - val_loss: 20075.4180\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20068.8125 - val_loss: 20054.1016\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20049.1406 - val_loss: 20031.6035\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 20022.5078 - val_loss: 20013.4609\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 20010.6406 - val_loss: 19995.4902\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 19991.0977 - val_loss: 19985.5762\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 19980.8770 - val_loss: 19966.7949\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 19961.1152 - val_loss: 19948.2031\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 19944.7598 - val_loss: 19930.5488\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 19924.4512 - val_loss: 19915.6484\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19911.7305 - val_loss: 19897.7012\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 19892.8652 - val_loss: 19881.5547\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 19877.8711 - val_loss: 19865.4336\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 19860.5273 - val_loss: 19849.5918\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19844.9961 - val_loss: 19833.7070\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19828.0879 - val_loss: 19817.8652\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 19810.8574 - val_loss: 19801.2715\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 19795.6797 - val_loss: 19784.4199\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19779.5508 - val_loss: 19766.9727\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 19761.6543 - val_loss: 19750.6152\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19744.1191 - val_loss: 19733.9238\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19728.3457 - val_loss: 19717.2539\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19713.5469 - val_loss: 19699.8301\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 19695.0723 - val_loss: 19684.2207\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19677.9629 - val_loss: 19667.7988\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19663.0801 - val_loss: 19650.9023\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 19644.8691 - val_loss: 19634.9785\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 19629.0879 - val_loss: 19618.0215\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 19612.3320 - val_loss: 19601.2988\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 19594.7148 - val_loss: 19584.2500\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 19580.0742 - val_loss: 19566.2227\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 19561.4746 - val_loss: 19549.4434\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19544.8086 - val_loss: 19532.9531\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 19528.1387 - val_loss: 19516.7090\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 19510.5000 - val_loss: 19500.4180\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 19493.5449 - val_loss: 19483.6973\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 19478.6562 - val_loss: 19466.1543\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 19460.8770 - val_loss: 19449.4336\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 19442.7949 - val_loss: 19433.2285\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19427.8750 - val_loss: 19416.2773\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19411.9883 - val_loss: 19399.2422\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19392.7773 - val_loss: 19382.9707\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 19377.5020 - val_loss: 19365.7207\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 19359.4375 - val_loss: 19348.5449\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 19342.6152 - val_loss: 19331.0625\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19324.2910 - val_loss: 19313.7480\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 19308.0254 - val_loss: 19296.0781\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19293.1523 - val_loss: 19278.4199\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19273.2812 - val_loss: 19262.2793\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 19257.4453 - val_loss: 19245.4570\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19239.7070 - val_loss: 19229.3613\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 19225.9551 - val_loss: 19212.5625\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 19208.2402 - val_loss: 19196.6895\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 19190.4902 - val_loss: 19181.0449\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 19176.0879 - val_loss: 19163.7109\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19157.8242 - val_loss: 19147.5918\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 19141.8652 - val_loss: 19130.7129\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 19125.2656 - val_loss: 19113.7754\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19109.6836 - val_loss: 19096.8672\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19090.9434 - val_loss: 19080.8906\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 19075.7812 - val_loss: 19063.9492\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 19058.2910 - val_loss: 19047.4824\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 19040.3340 - val_loss: 19030.7344\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 19025.1660 - val_loss: 19013.2422\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 19006.4180 - val_loss: 18996.4492\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 18990.1367 - val_loss: 18979.2070\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 18973.1641 - val_loss: 18962.6309\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 18958.6152 - val_loss: 18945.2168\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18939.4551 - val_loss: 18929.4023\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18923.8926 - val_loss: 18913.6133\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 18908.7852 - val_loss: 18897.0605\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 18891.4570 - val_loss: 18880.8828\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 18878.3145 - val_loss: 18863.6523\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 18857.4395 - val_loss: 18848.2129\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18845.3574 - val_loss: 18831.0469\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18825.6484 - val_loss: 18815.4434\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 18809.8750 - val_loss: 18799.5137\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 18795.8027 - val_loss: 18782.6641\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 18777.6875 - val_loss: 18768.1152\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 18762.9551 - val_loss: 18751.1387\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 18747.0977 - val_loss: 18735.0410\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18727.8477 - val_loss: 18719.9980\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18714.5703 - val_loss: 18702.2754\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18697.6152 - val_loss: 18685.2051\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 18679.5977 - val_loss: 18668.9551\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 18663.2637 - val_loss: 18652.8672\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18646.7012 - val_loss: 18636.6387\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 18632.5215 - val_loss: 18619.1797\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 18614.4922 - val_loss: 18602.5703\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 18596.4746 - val_loss: 18586.7930\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18580.5781 - val_loss: 18570.7695\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18564.2754 - val_loss: 18554.1074\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18547.9863 - val_loss: 18537.1348\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 18530.9277 - val_loss: 18520.0371\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 18514.9199 - val_loss: 18502.8848\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18497.7754 - val_loss: 18486.2227\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 18481.7227 - val_loss: 18469.4980\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 18463.0215 - val_loss: 18453.5176\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 18447.4727 - val_loss: 18437.1875\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 18431.2773 - val_loss: 18420.8770\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 18415.4160 - val_loss: 18405.0176\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 18399.5996 - val_loss: 18389.1289\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 18384.5664 - val_loss: 18372.2402\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 18368.0527 - val_loss: 18355.2012\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 18349.9082 - val_loss: 18339.1367\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 18333.8809 - val_loss: 18322.6797\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 18316.4590 - val_loss: 18306.4980\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 18300.9766 - val_loss: 18290.0449\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 18283.7363 - val_loss: 18273.9121\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 18267.2285 - val_loss: 18257.4121\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 18251.3477 - val_loss: 18240.6270\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 18234.2773 - val_loss: 18223.9238\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 18217.6387 - val_loss: 18207.2227\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 18201.8418 - val_loss: 18190.1445\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 18186.5332 - val_loss: 18172.9629\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 18166.2188 - val_loss: 18157.2188\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 18151.7676 - val_loss: 18140.2656\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 18134.7969 - val_loss: 18123.5547\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 18118.5215 - val_loss: 18107.3047\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 18102.6289 - val_loss: 18090.8477\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 18085.1504 - val_loss: 18074.8691\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 18068.9043 - val_loss: 18058.7734\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 18052.1523 - val_loss: 18042.7598\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 18038.7480 - val_loss: 18025.6035\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 18019.4785 - val_loss: 18009.6113\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 18003.1387 - val_loss: 17993.5547\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 17988.3809 - val_loss: 17976.5742\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 17971.6836 - val_loss: 17959.7070\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 43ms/step - loss: 17953.0820 - val_loss: 17943.5879\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 17939.1270 - val_loss: 17926.6621\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 17921.7852 - val_loss: 17910.1465\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17904.7031 - val_loss: 17893.6660\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 17888.8281 - val_loss: 17877.2695\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 17871.7930 - val_loss: 17861.2559\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17857.6504 - val_loss: 17844.9844\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 17840.4961 - val_loss: 17829.8281\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 17826.7441 - val_loss: 17813.8320\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 17809.4453 - val_loss: 17798.8652\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 17794.9199 - val_loss: 17783.4668\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 17778.7012 - val_loss: 17768.3848\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17764.1797 - val_loss: 17752.9707\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 17748.7656 - val_loss: 17737.7402\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 17732.3711 - val_loss: 17723.1582\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 17717.1465 - val_loss: 17707.7773\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 17701.0879 - val_loss: 17691.1152\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 17685.9707 - val_loss: 17673.8301\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 17669.5977 - val_loss: 17657.2852\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 17651.5586 - val_loss: 17641.5996\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 17634.6484 - val_loss: 17626.0625\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 17619.4922 - val_loss: 17609.6016\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 17604.4492 - val_loss: 17592.7090\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 17587.4707 - val_loss: 17576.4180\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 17571.0215 - val_loss: 17560.4727\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 17555.3848 - val_loss: 17544.9043\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 17539.4414 - val_loss: 17529.6113\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17524.2402 - val_loss: 17513.7598\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 17510.5234 - val_loss: 17497.6641\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 17492.0078 - val_loss: 17482.9082\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17476.5430 - val_loss: 17467.8613\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 17463.5703 - val_loss: 17451.5859\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 17445.4453 - val_loss: 17436.4062\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17431.9902 - val_loss: 17420.1074\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 17413.9863 - val_loss: 17405.0156\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 17399.3301 - val_loss: 17389.0508\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 17381.6445 - val_loss: 17373.3574\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 17367.3906 - val_loss: 17356.4785\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 17351.4238 - val_loss: 17339.7266\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 17332.9746 - val_loss: 17323.7930\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 17317.9316 - val_loss: 17306.7988\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 17301.7754 - val_loss: 17289.7715\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 17284.3672 - val_loss: 17273.5859\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 17268.3652 - val_loss: 17257.5176\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 17253.1875 - val_loss: 17241.3242\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 17237.4922 - val_loss: 17225.3262\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 17219.8613 - val_loss: 17210.1953\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 17204.3594 - val_loss: 17194.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc926537a60>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,validation_data=(X,y),epochs=200,batch_size=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4205939769744873"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.36358356],\n",
       "       [3.36358356],\n",
       "       [3.28757119],\n",
       "       [3.38258672],\n",
       "       [3.38258672],\n",
       "       [3.42059398]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict =  model.predict(X)\n",
    "test_predict  =  model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = pd.DataFrame({\"train_predict\":list(train_predict),'real':list(y)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_predict</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3.2762384]</td>\n",
       "      <td>3.124523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3.5164444]</td>\n",
       "      <td>3.420594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3.7095912]</td>\n",
       "      <td>3.772154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3.7857451]</td>\n",
       "      <td>3.610626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4.929466]</td>\n",
       "      <td>4.921854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[97.28772]</td>\n",
       "      <td>499.649994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[97.28772]</td>\n",
       "      <td>486.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[97.28771]</td>\n",
       "      <td>477.950012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[97.28771]</td>\n",
       "      <td>485.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[97.28771]</td>\n",
       "      <td>540.650024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_predict        real\n",
       "0    [3.2762384]    3.124523\n",
       "1    [3.5164444]    3.420594\n",
       "2    [3.7095912]    3.772154\n",
       "3    [3.7857451]    3.610626\n",
       "4     [4.929466]    4.921854\n",
       "..           ...         ...\n",
       "66    [97.28772]  499.649994\n",
       "67    [97.28772]  486.250000\n",
       "68    [97.28771]  477.950012\n",
       "69    [97.28771]  485.049988\n",
       "70    [97.28771]  540.650024\n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143.19295459882827"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143.19295459882827"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
