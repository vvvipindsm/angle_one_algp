{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging: Explore bagging algorithms in Python\n",
    "\n",
    "Import [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Random Forest Algorithm for Classification\n",
    "\n",
    "_In the last video, we talked about how Random Forest is the most popular algorithm that leverages bagging. So in this video we will explore some of the key hyperparameters for Random Forest! Again, we are only looking at the CLASSIFIER here since our titanic dataset is a classification problem but there is also a `RandomForestRegressor` tool in `sklearn`._\n",
    "\n",
    "_Lets start by importing `RandomForestClassifier` from `sklearn.ensemble` and then we will call the parameters in the same way we did with the boosting models, by calling the `get params` method._\n",
    "\n",
    "_So here are all of the potential hyperparameters we could tune and this might look a lot like Gradient Boosting. It's true, a lot of the hyperparameters are the same, because they are both tree based methods._\n",
    "\n",
    "_With that said, we're only goign to be focusing on **two** hyperparameters here._\n",
    "\n",
    "_Those two are `n estimators` or number of estimators and `max depth`. These two are defined the same way we did for Gradient Boosting:_\n",
    "* _`n estimators` is the number of base models, or the number of individual decision trees_\n",
    "* _`max depth` is the depth of each individual decision tree_\n",
    "\n",
    "_One difference I want to call out is that the `max depth` for Gradient boosting was set to 3 while the `max depth` set for Random Forest is `None`. That means that the decision tree can grow as deep as it needs to in order to find the optimal model. So by default, Random Forest will build 100 independent, really deep trees in parallel. Gradient Boosting, by default, will build 100 trees with a max depth of 3 - these trees will be built sequentially where each tree is trained on the mistake of prior trees. Remember - this all comes back to the bias variance tradeoff where boosting starts with high bias, low variance base models and reduces that bias through boosting. Bagging starts with low bias, high variance models and reduces the variance through bagging._\n",
    "\n",
    "_In the next lesson we will fit a Random Forest model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
