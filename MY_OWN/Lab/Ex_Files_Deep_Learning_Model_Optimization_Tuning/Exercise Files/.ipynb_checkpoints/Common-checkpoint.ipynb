{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5135ad02",
   "metadata": {},
   "source": [
    "The notebook contains a set of common functions used to run experiments for model optimization and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dbd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5616a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import yfinance\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Function to convert Flower names to numeric values\n",
    "#---------------------------------------------------------------------\n",
    "def type_to_numeric(x):\n",
    "    if x=='setosa':\n",
    "        return 0\n",
    "    if x=='versicolor':\n",
    "        return 1\n",
    "    else :\n",
    "        return 2\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Function to read data and process. Get ready for Deep Learning\n",
    "#---------------------------------------------------------------------\n",
    "def get_data(ticker,start_date):\n",
    "    data = yfinance.download(ticker, start=start_date)\n",
    "    \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_dime = scaler.fit_transform(data[['Close']])\n",
    "    scaled_data = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_data = scaled_data.fit_transform(data[['Close']])\n",
    "    sequence_length = 12\n",
    "    sequences,y_data = create_sequences(scaled_close_dime, sequence_length)\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(sequences) * 0.8)\n",
    "    test_size = len(sequences) - train_size\n",
    "    \n",
    "    train_data, test_data = sequences[:train_size], sequences[train_size:]\n",
    "    y_train, y_test = y_data[:train_size], y_data[train_size:]\n",
    "\n",
    "   # def handleData(data):\n",
    "        #lendf = data.shape[0] -1 \n",
    "        #if data[lendf - 1][0] > data[lendf][0]:\n",
    "         #   return 1\n",
    "        #else:\n",
    "       #     return 0\n",
    "      #  return 0\n",
    "\n",
    "    #y_train = train_data\n",
    "\n",
    "    #y_test = test_data\n",
    "    #Use a Label encoder to convert String to numeric values for the target variable\n",
    "    # Separate input (X) and output (y) variables\n",
    "    \n",
    "  \n",
    "   # y_test = tf.keras.utils.to_categorical(y_test,2)\n",
    "   # y_train = tf.keras.utils.to_categorical(y_train,2)\n",
    "   # y_test = tf.keras.utils.to_categorical(y_test,2)\n",
    "    #y_train = tf.keras.utils.to_categorical(y_train,2)\n",
    "\n",
    "      \n",
    "    \n",
    "    print(train_data.shape,test_data.shape,y_train.shape,y_test.shape)\n",
    "    \n",
    "    \n",
    "    #Return Feature and Target variables\n",
    "    return train_data,test_data,y_train,y_test\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Function to create the default configuration for the model. This will be overridden as \n",
    "#required during experimentation\n",
    "#---------------------------------------------------------------------\n",
    "def base_model_config():\n",
    "    model_config = {\n",
    "            \"HIDDEN_NODES\" : [32,64],\n",
    "            \"HIDDEN_ACTIVATION\" : \"relu\",\n",
    "            \"OUTPUT_NODES\" : 1,\n",
    "            \"OUTPUT_ACTIVATION\" : \"softmax\",\n",
    "            \"WEIGHTS_INITIALIZER\" : \"random_normal\",\n",
    "            \"BIAS_INITIALIZER\" : \"zeros\",\n",
    "            \"NORMALIZATION\" : \"batch\", #\"none\"\n",
    "            \"OPTIMIZER\" : \"rmsprop\",\n",
    "            \"LEARNING_RATE\" : 0.001,\n",
    "            \"REGULARIZER\" : None,\n",
    "            \"DROPOUT_RATE\" : 0.0,\n",
    "            \"EPOCHS\" : 200,\n",
    "            \"BATCH_SIZE\" : 16,\n",
    "            \"VALIDATION_SPLIT\" : 0.2,\n",
    "            \"VERBOSE\" : 0,\n",
    "            \"LOSS_FUNCTION\" : \"categorical_crossentropy\",\n",
    "            \"METRICS\" : [\"accuracy\"]\n",
    "            }\n",
    "    return model_config\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Function to create an optimizer based on the optimizer name and learning rate\n",
    "#---------------------------------------------------------------------\n",
    "def get_optimizer(optimizer_name, learning_rate):\n",
    "    #'sgd','rmsprop','adam','adagrad'\n",
    "    optimizer=None\n",
    "    \n",
    "    if optimizer_name == 'adagrad': \n",
    "        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "\n",
    "    elif 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    elif'adam' :\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "    else :\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "            \n",
    "    return optimizer\n",
    "    \n",
    "# Function to create sequences for time series prediction\n",
    "def create_sequences(data, sequence_length):\n",
    "    x_seq = []\n",
    "    y_data = []\n",
    "    for i in range(len(data) - (sequence_length +1)):\n",
    "        if 2 == 2:\n",
    "            seq = data[i : i + sequence_length]\n",
    "            x_seq.append(seq)\n",
    "            y_data.append(data[(i + sequence_length)+1][0])\n",
    "            \n",
    "    return np.array(x_seq),np.array(y_data)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "# Function to create a model and fit the model\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "def create_and_run_model(model_config,X,Y,model_name,X_val,Y_val,is_prod = False):\n",
    "    input_dim = X.shape[1] \n",
    "    print(input_dim)\n",
    "    model = tf.keras.models.Sequential(name = model_name)\n",
    "     \n",
    "    for layer in range(len(model_config[\"HIDDEN_NODES\"])):\n",
    "        \n",
    "        if (layer == 0):\n",
    "            input_dim\n",
    "            model.add(\n",
    "                    keras.layers.Dense(model_config[\"HIDDEN_NODES\"][layer],\n",
    "                    input_shape=(input_dim,),\n",
    "                    name=\"Dense-Layer-\" + str(layer),\n",
    "                    kernel_initializer = model_config[\"WEIGHTS_INITIALIZER\"],\n",
    "                    bias_initializer = model_config[\"BIAS_INITIALIZER\"],\n",
    "                    kernel_regularizer=model_config[\"REGULARIZER\"],\n",
    "                    activation=model_config[\"HIDDEN_ACTIVATION\"]))\n",
    "        else:\n",
    "            \n",
    "            if ( model_config[\"NORMALIZATION\"] == \"batch\"):\n",
    "                model.add(keras.layers.BatchNormalization())\n",
    "                \n",
    "            if ( model_config[\"DROPOUT_RATE\"] > 0.0 ):\n",
    "                model.add(keras.layers.Dropout(model_config[\"DROPOUT_RATE\"]))\n",
    "                \n",
    "            model.add(\n",
    "                    keras.layers.Dense(model_config[\"HIDDEN_NODES\"][layer],\n",
    "                    name=\"Dense-Layer-\" + str(layer),\n",
    "                    kernel_initializer = model_config[\"WEIGHTS_INITIALIZER\"],\n",
    "                    bias_initializer = model_config[\"BIAS_INITIALIZER\"],\n",
    "                    kernel_regularizer=model_config[\"REGULARIZER\"],\n",
    "                    activation=model_config[\"HIDDEN_ACTIVATION\"])) \n",
    "            \n",
    "\n",
    "            \n",
    "    model.add(keras.layers.Dense(model_config[\"OUTPUT_NODES\"],\n",
    "                    name=\"Output-Layer\",\n",
    "                    activation=model_config[\"OUTPUT_ACTIVATION\"]))\n",
    "    \n",
    "    optimizer = get_optimizer( model_config[\"OPTIMIZER\"],\n",
    "                              model_config[\"LEARNING_RATE\"])\n",
    "    \n",
    "    model.compile(loss      = model_config[\"LOSS_FUNCTION\"],\n",
    "                  optimizer = optimizer,\n",
    "                  metrics   = model_config[\"METRICS\"]\n",
    "                 )\n",
    "    \n",
    "    print(\"\\n******************************************************\")\n",
    "    model.summary()\n",
    "    print(X.shape)\n",
    "    #print(\"y shape : \",Y.reshape(-1, input_dim).shape)\n",
    "    history=model.fit(X,\n",
    "          Y,\n",
    "          batch_size=model_config[\"BATCH_SIZE\"],\n",
    "          epochs=model_config[\"EPOCHS\"],\n",
    "          verbose=model_config[\"VERBOSE\"],\n",
    "          validation_data= (X_val, Y_val))\n",
    "    \n",
    "    if is_prod == True:\n",
    "        return model\n",
    "    \n",
    "    return history\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "#Function to plot a graph based on the results derived\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "def plot_graph(accuracy_measures, title):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for experiment in accuracy_measures.keys():\n",
    "        plt.plot(accuracy_measures[experiment], \n",
    "                 label=experiment,\n",
    "                    linewidth=3)\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
