{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data Find Future list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from dataProcessing import DataProcessing\n",
    "# Remove Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avg_Range', 'TARGET']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findFeature = False\n",
    "#tickers = [\"OLECTRA.NS\",\"LT.NS\",\"CONCOR.NS\",\"ELGIEQUIP.NS\",\"IOC.NS\",\"BEL.NS\",\"TATAELXSI.NS\",\"^NSEI\"]\n",
    "\n",
    "features = [\"Avg_Range\"]\n",
    "features.append(\"TARGET\")\n",
    "symbol = \"^NSEI\"\n",
    "df = pd.read_csv(\"../stock_historical_data/{}.csv\".format(symbol))\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dataProcessing.DataProcessing object at 0x7ff013034310>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/workspace/ai/my_own/MY_OWN/LoadingNdRun/stratmanagerDaily.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Returns\"] = df[\"Close\"].pct_change()\n",
      "/Users/vipin/workspace/ai/my_own/MY_OWN/LoadingNdRun/stratmanagerDaily.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Range\"] = df[\"High\"] / df[\"Low\"] - 1\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/vipin/workspace/ai/my_own/MY_OWN/LoadingNdRun/stratmanagerDaily.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Bench_C_Rets\"], sharpe = self._calculate_returns(df, True)\n",
      "/Users/vipin/workspace/ai/my_own/MY_OWN/LoadingNdRun/stratmanagerDaily.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#strat_mgr = StrategyManager(symbol, \"\", \"\",concatenated_df)\n",
    "data = DataProcessing(symbol,df)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = data.df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>Bench_C_Rets</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>MA_12</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-29</th>\n",
       "      <td>-2.687478</td>\n",
       "      <td>-0.857076</td>\n",
       "      <td>-0.867172</td>\n",
       "      <td>5904.100098</td>\n",
       "      <td>-1.310941</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.386621</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>56.873757</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>5730.737508</td>\n",
       "      <td>5753.211937</td>\n",
       "      <td>0.161021</td>\n",
       "      <td>-0.156026</td>\n",
       "      <td>0.013603</td>\n",
       "      <td>0.288672</td>\n",
       "      <td>1.090742</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>-1.311491</td>\n",
       "      <td>1.002975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-02</th>\n",
       "      <td>-0.048176</td>\n",
       "      <td>3.881063</td>\n",
       "      <td>4.192497</td>\n",
       "      <td>5999.350098</td>\n",
       "      <td>-1.378812</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>0.303455</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>62.174531</td>\n",
       "      <td>1.093202</td>\n",
       "      <td>5757.137533</td>\n",
       "      <td>5766.528599</td>\n",
       "      <td>0.163494</td>\n",
       "      <td>-0.188867</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.386621</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.013603</td>\n",
       "      <td>0.288672</td>\n",
       "      <td>1.090742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-06</th>\n",
       "      <td>1.269143</td>\n",
       "      <td>-1.413804</td>\n",
       "      <td>-1.038976</td>\n",
       "      <td>5971.049805</td>\n",
       "      <td>-5.065963</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>12.838596</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>59.821824</td>\n",
       "      <td>0.962160</td>\n",
       "      <td>5779.358358</td>\n",
       "      <td>5779.507161</td>\n",
       "      <td>0.172144</td>\n",
       "      <td>0.313399</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>0.303455</td>\n",
       "      <td>1.093202</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.386621</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-07</th>\n",
       "      <td>-1.799699</td>\n",
       "      <td>-4.121651</td>\n",
       "      <td>-33.073542</td>\n",
       "      <td>6043.549805</td>\n",
       "      <td>-1.973705</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.346882</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>63.619800</td>\n",
       "      <td>1.063488</td>\n",
       "      <td>5803.979167</td>\n",
       "      <td>5791.854771</td>\n",
       "      <td>0.189355</td>\n",
       "      <td>0.292789</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>12.838596</td>\n",
       "      <td>0.962160</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>0.303455</td>\n",
       "      <td>1.093202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-08</th>\n",
       "      <td>1.079875</td>\n",
       "      <td>-0.558843</td>\n",
       "      <td>-0.236378</td>\n",
       "      <td>6069.299805</td>\n",
       "      <td>-1.434796</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>-0.221885</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.889280</td>\n",
       "      <td>1.019954</td>\n",
       "      <td>5847.841634</td>\n",
       "      <td>5801.664295</td>\n",
       "      <td>0.189436</td>\n",
       "      <td>0.302974</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.346882</td>\n",
       "      <td>1.063488</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>12.838596</td>\n",
       "      <td>0.962160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>-1.613425</td>\n",
       "      <td>-1.953067</td>\n",
       "      <td>-1.002986</td>\n",
       "      <td>18691.199219</td>\n",
       "      <td>-7.692646</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>84.290311</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>61.740370</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>18662.024902</td>\n",
       "      <td>18492.666667</td>\n",
       "      <td>0.105103</td>\n",
       "      <td>2.674456</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>-0.732807</td>\n",
       "      <td>1.014003</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>-0.292459</td>\n",
       "      <td>0.992899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>-2.116168</td>\n",
       "      <td>-4.126554</td>\n",
       "      <td>-169.715818</td>\n",
       "      <td>18817.400391</td>\n",
       "      <td>-2.601690</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>65.282167</td>\n",
       "      <td>1.057366</td>\n",
       "      <td>18703.379069</td>\n",
       "      <td>18519.409505</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>2.686028</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>84.290311</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>-0.732807</td>\n",
       "      <td>1.014003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>1.402315</td>\n",
       "      <td>0.688108</td>\n",
       "      <td>1.169755</td>\n",
       "      <td>18972.099609</td>\n",
       "      <td>1.651000</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.062869</td>\n",
       "      <td>1.057913</td>\n",
       "      <td>18742.774902</td>\n",
       "      <td>18562.414249</td>\n",
       "      <td>0.114116</td>\n",
       "      <td>2.683200</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>1.057366</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>84.290311</td>\n",
       "      <td>0.875659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.048093</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.101137</td>\n",
       "      <td>19189.050781</td>\n",
       "      <td>-1.477542</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.157412</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>73.432364</td>\n",
       "      <td>1.063268</td>\n",
       "      <td>18797.354167</td>\n",
       "      <td>18606.445219</td>\n",
       "      <td>0.125228</td>\n",
       "      <td>2.586896</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>1.057913</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>1.057366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-0.254509</td>\n",
       "      <td>0.274122</td>\n",
       "      <td>19322.550781</td>\n",
       "      <td>-0.767595</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>-0.322797</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>75.706160</td>\n",
       "      <td>1.030964</td>\n",
       "      <td>18857.650065</td>\n",
       "      <td>18656.759580</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>2.586301</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.157412</td>\n",
       "      <td>1.063268</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>1.057913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High         Low         Close    Volume   Returns  \\\n",
       "Date                                                                           \n",
       "2013-04-29 -2.687478 -0.857076   -0.867172   5904.100098 -1.310941  0.005561   \n",
       "2013-05-02 -0.048176  3.881063    4.192497   5999.350098 -1.378812  0.011661   \n",
       "2013-05-06  1.269143 -1.413804   -1.038976   5971.049805 -5.065963  0.004551   \n",
       "2013-05-07 -1.799699 -4.121651  -33.073542   6043.549805 -1.973705  0.012142   \n",
       "2013-05-08  1.079875 -0.558843   -0.236378   6069.299805 -1.434796  0.004261   \n",
       "...              ...       ...         ...           ...       ...       ...   \n",
       "2023-06-26 -1.613425 -1.953067   -1.002986  18691.199219 -7.692646  0.001377   \n",
       "2023-06-27 -2.116168 -4.126554 -169.715818  18817.400391 -2.601690  0.006752   \n",
       "2023-06-28  1.402315  0.688108    1.169755  18972.099609  1.651000  0.008221   \n",
       "2023-06-30  0.048093  0.036407    0.101137  19189.050781 -1.477542  0.011435   \n",
       "2023-07-03 -0.003255 -0.254509    0.274122  19322.550781 -0.767595  0.006957   \n",
       "\n",
       "                Range  Bench_C_Rets        RSI   RSI_Ret         MA_12  \\\n",
       "Date                                                                     \n",
       "2013-04-29   0.386621          -1.0  56.873757  0.983333   5730.737508   \n",
       "2013-05-02   0.303455          -1.0  62.174531  1.093202   5757.137533   \n",
       "2013-05-06  12.838596          -1.0  59.821824  0.962160   5779.358358   \n",
       "2013-05-07   0.346882          -1.0  63.619800  1.063488   5803.979167   \n",
       "2013-05-08  -0.221885          -1.0  64.889280  1.019954   5847.841634   \n",
       "...               ...           ...        ...       ...           ...   \n",
       "2023-06-26  84.290311          -1.0  61.740370  0.875659  18662.024902   \n",
       "2023-06-27   0.580556          -1.0  65.282167  1.057366  18703.379069   \n",
       "2023-06-28   0.229700          -1.0  69.062869  1.057913  18742.774902   \n",
       "2023-06-30   0.157412          -1.0  73.432364  1.063268  18797.354167   \n",
       "2023-07-03  -0.322797          -1.0  75.706160  1.030964  18857.650065   \n",
       "\n",
       "                   MA_21  Roll_Rets  Avg_Range  Returns_T1   Range_T1  \\\n",
       "Date                                                                    \n",
       "2013-04-29   5753.211937   0.161021  -0.156026    0.013603   0.288672   \n",
       "2013-05-02   5766.528599   0.163494  -0.188867    0.005561   0.386621   \n",
       "2013-05-06   5779.507161   0.172144   0.313399    0.011661   0.303455   \n",
       "2013-05-07   5791.854771   0.189355   0.292789    0.004551  12.838596   \n",
       "2013-05-08   5801.664295   0.189436   0.302974    0.012142   0.346882   \n",
       "...                  ...        ...        ...         ...        ...   \n",
       "2023-06-26  18492.666667   0.105103   2.674456    0.002134  -0.732807   \n",
       "2023-06-27  18519.409505   0.106771   2.686028    0.001377  84.290311   \n",
       "2023-06-28  18562.414249   0.114116   2.683200    0.006752   0.580556   \n",
       "2023-06-30  18606.445219   0.125228   2.586896    0.008221   0.229700   \n",
       "2023-07-03  18656.759580   0.132208   2.586301    0.011435   0.157412   \n",
       "\n",
       "            RSI_Ret_T1  Returns_T2   Range_T2  RSI_Ret_T2  \n",
       "Date                                                       \n",
       "2013-04-29    1.090742    0.000428  -1.311491    1.002975  \n",
       "2013-05-02    0.983333    0.013603   0.288672    1.090742  \n",
       "2013-05-06    1.093202    0.005561   0.386621    0.983333  \n",
       "2013-05-07    0.962160    0.011661   0.303455    1.093202  \n",
       "2013-05-08    1.063488    0.004551  12.838596    0.962160  \n",
       "...                ...         ...        ...         ...  \n",
       "2023-06-26    1.014003    0.003266  -0.292459    0.992899  \n",
       "2023-06-27    0.875659    0.002134  -0.732807    1.014003  \n",
       "2023-06-28    1.057366    0.001377  84.290311    0.875659  \n",
       "2023-06-30    1.057913    0.006752   0.580556    1.057366  \n",
       "2023-07-03    1.063268    0.008221   0.229700    1.057913  \n",
       "\n",
       "[1352 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Target\n",
    "df_f.loc[df_f[\"Range\"].shift(-1) > df_f[\"Avg_Range\"], \"TARGET\"] = 1\n",
    "df_f.loc[df_f[\"Range\"].shift(-1) <= df_f[\"Avg_Range\"], \"TARGET\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>Bench_C_Rets</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>-1.613425</td>\n",
       "      <td>-1.953067</td>\n",
       "      <td>-1.002986</td>\n",
       "      <td>18691.199219</td>\n",
       "      <td>-7.692646</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>84.290311</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>61.740370</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>...</td>\n",
       "      <td>18492.666667</td>\n",
       "      <td>0.105103</td>\n",
       "      <td>2.674456</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>-0.732807</td>\n",
       "      <td>1.014003</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>-0.292459</td>\n",
       "      <td>0.992899</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>-2.116168</td>\n",
       "      <td>-4.126554</td>\n",
       "      <td>-169.715818</td>\n",
       "      <td>18817.400391</td>\n",
       "      <td>-2.601690</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>65.282167</td>\n",
       "      <td>1.057366</td>\n",
       "      <td>...</td>\n",
       "      <td>18519.409505</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>2.686028</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>84.290311</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>-0.732807</td>\n",
       "      <td>1.014003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>1.402315</td>\n",
       "      <td>0.688108</td>\n",
       "      <td>1.169755</td>\n",
       "      <td>18972.099609</td>\n",
       "      <td>1.651000</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.062869</td>\n",
       "      <td>1.057913</td>\n",
       "      <td>...</td>\n",
       "      <td>18562.414249</td>\n",
       "      <td>0.114116</td>\n",
       "      <td>2.683200</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>1.057366</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>84.290311</td>\n",
       "      <td>0.875659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.048093</td>\n",
       "      <td>0.036407</td>\n",
       "      <td>0.101137</td>\n",
       "      <td>19189.050781</td>\n",
       "      <td>-1.477542</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.157412</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>73.432364</td>\n",
       "      <td>1.063268</td>\n",
       "      <td>...</td>\n",
       "      <td>18606.445219</td>\n",
       "      <td>0.125228</td>\n",
       "      <td>2.586896</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>1.057913</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>1.057366</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-0.254509</td>\n",
       "      <td>0.274122</td>\n",
       "      <td>19322.550781</td>\n",
       "      <td>-0.767595</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>-0.322797</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>75.706160</td>\n",
       "      <td>1.030964</td>\n",
       "      <td>...</td>\n",
       "      <td>18656.759580</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>2.586301</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.157412</td>\n",
       "      <td>1.063268</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>1.057913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High         Low         Close    Volume   Returns  \\\n",
       "Date                                                                           \n",
       "2023-06-26 -1.613425 -1.953067   -1.002986  18691.199219 -7.692646  0.001377   \n",
       "2023-06-27 -2.116168 -4.126554 -169.715818  18817.400391 -2.601690  0.006752   \n",
       "2023-06-28  1.402315  0.688108    1.169755  18972.099609  1.651000  0.008221   \n",
       "2023-06-30  0.048093  0.036407    0.101137  19189.050781 -1.477542  0.011435   \n",
       "2023-07-03 -0.003255 -0.254509    0.274122  19322.550781 -0.767595  0.006957   \n",
       "\n",
       "                Range  Bench_C_Rets        RSI   RSI_Ret  ...         MA_21  \\\n",
       "Date                                                      ...                 \n",
       "2023-06-26  84.290311          -1.0  61.740370  0.875659  ...  18492.666667   \n",
       "2023-06-27   0.580556          -1.0  65.282167  1.057366  ...  18519.409505   \n",
       "2023-06-28   0.229700          -1.0  69.062869  1.057913  ...  18562.414249   \n",
       "2023-06-30   0.157412          -1.0  73.432364  1.063268  ...  18606.445219   \n",
       "2023-07-03  -0.322797          -1.0  75.706160  1.030964  ...  18656.759580   \n",
       "\n",
       "            Roll_Rets  Avg_Range  Returns_T1   Range_T1  RSI_Ret_T1  \\\n",
       "Date                                                                  \n",
       "2023-06-26   0.105103   2.674456    0.002134  -0.732807    1.014003   \n",
       "2023-06-27   0.106771   2.686028    0.001377  84.290311    0.875659   \n",
       "2023-06-28   0.114116   2.683200    0.006752   0.580556    1.057366   \n",
       "2023-06-30   0.125228   2.586896    0.008221   0.229700    1.057913   \n",
       "2023-07-03   0.132208   2.586301    0.011435   0.157412    1.063268   \n",
       "\n",
       "            Returns_T2   Range_T2  RSI_Ret_T2  TARGET  \n",
       "Date                                                   \n",
       "2023-06-26    0.003266  -0.292459    0.992899     0.0  \n",
       "2023-06-27    0.002134  -0.732807    1.014003     0.0  \n",
       "2023-06-28    0.001377  84.290311    0.875659     0.0  \n",
       "2023-06-30    0.006752   0.580556    1.057366     0.0  \n",
       "2023-07-03    0.008221   0.229700    1.057913     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "nan_location = np.where(np.isnan(df_f))\n",
    "nan_location\n",
    "# Fill NA\n",
    "df_f[\"TARGET\"].fillna(0, inplace=True)\n",
    "df_f.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame does not contain NaN values\n"
     ]
    }
   ],
   "source": [
    "# Remove unwanted columns\n",
    "df_tts = df_f.copy()\n",
    "df_tts.drop(columns=[\"Close\", \"Bench_C_Rets\", \"Open\", \"High\", \"Low\"], inplace=True)\n",
    "# Find columns with infinite values\n",
    "columns_with_inf = df_tts.columns[np.isinf(df_tts).any()]\n",
    "\n",
    "#Drop columns with infinite values\n",
    "df_tts.drop(columns_with_inf, axis=1, inplace=True)\n",
    "has_inf = np.isinf(df_tts.values).any()\n",
    "\n",
    "if has_inf:\n",
    "    print(\"DataFrame contains NaN values\",columns_with_inf)\n",
    "else:\n",
    "    print(\"DataFrame does not contain NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-29</th>\n",
       "      <td>-0.156026</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-02</th>\n",
       "      <td>-0.188867</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-06</th>\n",
       "      <td>0.313399</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-07</th>\n",
       "      <td>0.292789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-08</th>\n",
       "      <td>0.302974</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>2.674456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>2.686028</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>2.683200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>2.586896</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>2.586301</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1352 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg_Range  TARGET\n",
       "Date                         \n",
       "2013-04-29  -0.156026     1.0\n",
       "2013-05-02  -0.188867     1.0\n",
       "2013-05-06   0.313399     1.0\n",
       "2013-05-07   0.292789     0.0\n",
       "2013-05-08   0.302974     1.0\n",
       "...               ...     ...\n",
       "2023-06-26   2.674456     0.0\n",
       "2023-06-27   2.686028     0.0\n",
       "2023-06-28   2.683200     0.0\n",
       "2023-06-30   2.586896     0.0\n",
       "2023-07-03   2.586301     0.0\n",
       "\n",
       "[1352 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Feature Selection\n",
    "df_tts = df_tts.copy()\n",
    "if findFeature == False:\n",
    "    df_tts = df_tts[features]\n",
    "df_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (1081, 1)\n",
      "Shape of y_train:  (1081,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Params >> ne: 25, lr: 0.3 md: 3 gm: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# Perform Train Test Split\n",
    "# Split into Learning (X) and Target (y) Data\n",
    "X = df_tts.iloc[:, : -1]\n",
    "y = df_tts.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "\n",
    "# Select type of model to optimize for\n",
    "is_binary = True\n",
    "is_optimise_for_precision = True\n",
    "# Determine Objective and Eval Metrics\n",
    "if is_binary:\n",
    "    objective = \"binary:logistic\"\n",
    "    eval_metric = \"logloss\"\n",
    "    eval_metric_list = [\"error\", \"logloss\", eval_metric]\n",
    "else:\n",
    "    objective = \"multi:softmax\"\n",
    "    eval_metric = \"mlogloss\"\n",
    "    eval_metric_list = [\"merror\", \"mlogloss\", eval_metric]\n",
    "# Refine Eval Metric\n",
    "if is_binary and is_optimise_for_precision:\n",
    "    eval_metric = \"aucpr\"\n",
    "    scoring = \"precision\"\n",
    "elif is_binary and not is_optimise_for_precision:\n",
    "    eval_metric = \"auc\"\n",
    "    scoring = \"f1\"\n",
    "else:\n",
    "    scoring = \"accuracy\"\n",
    "# Build First Classifier Model 0\n",
    "classifier_0 = XGBClassifier(\n",
    "    objective=objective,\n",
    "    booster=\"gbtree\",\n",
    "    eval_metric=eval_metric,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "# Provide Gris for Hyperparams\n",
    "param_grid = {\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.5, 1, 1.5, 2, 3, 6, 12, 20],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 8, 12],\n",
    "    \"n_estimators\": [25, 50, 65, 80, 100, 115, 200]\n",
    "}\n",
    "grid_search = RandomizedSearchCV(estimator=classifier_0, param_distributions=param_grid, scoring=scoring)\n",
    "\n",
    "# Perform Random Search for Best Hyper params\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "hyperparams = best_model.best_params_\n",
    "ne = hyperparams[\"n_estimators\"]\n",
    "lr = hyperparams[\"learning_rate\"]\n",
    "md = hyperparams[\"max_depth\"]\n",
    "gm = hyperparams[\"gamma\"]\n",
    "print(\"Recommended Params >>\", f\"ne: {ne},\", f\"lr: {lr}\", f\"md: {md}\", f\"gm: {gm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# Build Classification Model 1\n",
    "classifier_1 = XGBClassifier(\n",
    "    objective=objective,\n",
    "    booster=\"gbtree\",\n",
    "    eval_metric=eval_metric,\n",
    "    n_estimators=ne,\n",
    "    learning_rate=lr,\n",
    "    max_depth=md,\n",
    "    gamma=gm,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=1,\n",
    "    use_label_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "eval_set = [(X_train, y_train)]\n",
    "classifier_1.set_params(eval_metric=eval_metric_list)  # Example metric: 'error'\n",
    "\n",
    "classifier_1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #eval_metric=eval_metric_list,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Preds: \n",
      " [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for training data\n",
    "train_yhat = classifier_1.predict(X_train)\n",
    "print(\"Training Preds: \\n\", train_yhat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_Range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>-0.556008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-03</th>\n",
       "      <td>0.845862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-20</th>\n",
       "      <td>0.230059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-14</th>\n",
       "      <td>2.732040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-16</th>\n",
       "      <td>2.144926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-02</th>\n",
       "      <td>-0.169858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14</th>\n",
       "      <td>-2.766191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-23</th>\n",
       "      <td>-0.664681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>2.304092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-07</th>\n",
       "      <td>0.011268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg_Range\n",
       "Date                 \n",
       "2020-09-15  -0.556008\n",
       "2020-07-03   0.845862\n",
       "2014-03-20   0.230059\n",
       "2018-09-14   2.732040\n",
       "2022-05-16   2.144926\n",
       "...               ...\n",
       "2021-08-02  -0.169858\n",
       "2021-10-14  -2.766191\n",
       "2023-01-23  -0.664681\n",
       "2019-12-12   2.304092\n",
       "2021-10-07   0.011268\n",
       "\n",
       "[1081 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set K-Fold Cross Validation Levels\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "train_results = cross_val_score(classifier_1, X_train, y_train, scoring=scoring, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy K-Fold:  0.7\n",
      "Std Deviation K-Fold:  0.03\n",
      "Precision Score 0:  0.778\n",
      "Precision Score 1:  0.707\n",
      "\n",
      "Just for reference. Right now, we are only focussed on getting some initial features.\n",
      "If the results look too good to be true, they probably are.\n"
     ]
    }
   ],
   "source": [
    "# Brief Review of Training Results\n",
    "print(\"Average Accuracy K-Fold: \", round(train_results.mean(), 2))\n",
    "print(\"Std Deviation K-Fold: \", round(train_results.std(), 2))\n",
    "print(\"Precision Score 0: \", round(precision_score(y_train, train_yhat, average=None)[0], 3))\n",
    "print(\"Precision Score 1: \", round(precision_score(y_train, train_yhat, average=None)[1], 3))\n",
    "print(\"\")\n",
    "print(\"Just for reference. Right now, we are only focussed on getting some initial features.\")\n",
    "print(\"If the results look too good to be true, they probably are.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_1.fit(\n",
    "    X,\n",
    "    y,\n",
    "    #eval_metric=eval_metric_list,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Feature Importances\n",
    "fig = plt.figure(figsize=(22, 5))\n",
    "importance_labels = X.columns\n",
    "importance_features = classifier_1.feature_importances_\n",
    "plt.bar(importance_labels, importance_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Features\n",
    "mean_feature_importance = importance_features.mean()\n",
    "i = 0\n",
    "recommended_feature_labels = []\n",
    "recommended_feature_score = []\n",
    "for fi in importance_features:\n",
    "    if fi > mean_feature_importance:\n",
    "        recommended_feature_labels.append(importance_labels[i])\n",
    "        recommended_feature_score.append(fi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "if findFeature == False:\n",
    "    with open('../TrainedModel/xg/{}_model_2.pkl'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(classifier_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "if findFeature == True:\n",
    "    print(recommended_feature_labels)\n",
    "    with open('../TrainedModel/xg/{}_features.txt'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(recommended_feature_labels, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
