{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from dataProcessing import DataProcessing\n",
    "# Remove Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_setup_data(sybmol,input_data):\n",
    "    df = pd.read_csv(\"../stock_historical_data/{}.csv\".format(sybmol))\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    new_data = pd.DataFrame(input_data)\n",
    "    new_data.set_index(\"Date\", inplace=True)\n",
    "    concatenated_df = pd.concat([df,new_data])\n",
    "    return concatenated_df\n",
    "\n",
    "def fetch_stock_data(tickers):\n",
    "    data = yfinance.download(tickers,period='1d')\n",
    "    print(data)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_stock_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m final_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     15\u001b[0m final_target \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 16\u001b[0m stock_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_stock_data\u001b[49m(symbols)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(stock_data)\n\u001b[1;32m     18\u001b[0m finaldata \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fetch_stock_data' is not defined"
     ]
    }
   ],
   "source": [
    "symbols = [\"OLECTRA.NS\",\"LT.NS\",\"CONCOR.NS\",\"ELGIEQUIP.NS\",\"IOC.NS\",\"BEL.NS\",\"TATAELXSI.NS\",\"^NSEI\"]\n",
    "\n",
    "Icdate = 0\n",
    "Iresult = 1\n",
    "IisClassification = 2\n",
    "Imodel = 3\n",
    "Istock = 4\n",
    "Iclose = 5\n",
    "Iprob = 6\n",
    "  # Add the tickers you want to fetch data for\n",
    "loaded_models = {}\n",
    "result = []\n",
    "\n",
    "final_result = {}\n",
    "final_target = {}\n",
    "stock_data = fetch_stock_data(symbols)\n",
    "print(stock_data)\n",
    "finaldata = {}\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "\n",
    "for symbol in symbols:\n",
    "    stock_name = symbol\n",
    "    if symbol == \"^NSEI\":\n",
    "        stock_name = \"NSEI\"\n",
    " \n",
    "    input_data = {\n",
    "                    # \"Open\" : stock_data.head(1).Open[ticker].values[0],\n",
    "                    \"Open\" : [stock_data.head(1).Open[symbol].values[0]],\n",
    "                    \"Close\" : [stock_data.head(1).Close[symbol].values[0]],\n",
    "                    \"High\" : [stock_data.head(1).High[symbol].values[0]],\n",
    "                    \"Low\" : [stock_data.head(1).Low[symbol].values[0]], \n",
    "                    \"Volume\" : [stock_data.head(1).Volume[symbol].values[0]],\n",
    "                    \"Date\":[np.datetime_as_string(stock_data.index, unit='D')[0]]\n",
    "    }\n",
    "    print(input_data)\n",
    "    data = load_and_setup_data(symbol,input_data)\n",
    "    data.to_csv(f\"../stock_historical_data/{symbol}.csv\")\n",
    "    data = DataProcessing(symbol,data)\n",
    "    # Specify Target\n",
    "    data.df.loc[data.df[\"Range\"].shift(-1) > data.df[\"Avg_Range\"], \"TARGET\"] = 1\n",
    "    data.df.loc[data.df[\"Range\"].shift(-1) <= data.df[\"Avg_Range\"], \"TARGET\"] = 0\n",
    "    loaded_model = {}\n",
    "    feature_item = {}\n",
    "    with open('../TrainedModel/xg/{}_model_2.pkl'.format(symbol), 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    with open('../TrainedModel/xg/{}_features.txt'.format(symbol), 'rb') as f:\n",
    "        feature_item = pickle.load(f)\n",
    "    #final training\n",
    "    loaded_models[symbol] = loaded_model\n",
    "    data.df = data.df.dropna()\n",
    "\n",
    "    final_target[symbol] = data.df[\"TARGET\"]\n",
    "    df = data.df[feature_item]\n",
    "    finaldata[symbol]= df \n",
    "    stock_name_only = stock_name.replace(\".NS\",\"\")\n",
    "    train_yhat = loaded_model.predict(df[-1:])\n",
    "    train_yhat_proba = loaded_model.predict_proba(df[-1:])\n",
    "    greater = 0\n",
    "    one = train_yhat_proba[0][0]\n",
    "    two = train_yhat_proba[0][1]\n",
    "    if one > two:\n",
    "        greater = one*100\n",
    "    else:\n",
    "        greater = one*100\n",
    "#    print(greater)\n",
    "    final_result[symbol] = [current_date,train_yhat[0],1,'xg',stock_name_only,stock_data.head(1).Close[symbol].values[0],round(greater,2)]\n",
    "    result.append([current_date,train_yhat[0],1,'xg',stock_name_only,stock_data.head(1).Close[symbol].values[0],round(greater,2)])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '1043.949951171875',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'OLECTRA',\n",
       "   'prob': '88.93'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '2490.199951171875',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'LT',\n",
       "   'prob': '51.86'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '1',\n",
       "   'pre_close': '689.8499755859375',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'CONCOR',\n",
       "   'prob': '45.15'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '540.0',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'ELGIEQUIP',\n",
       "   'prob': '90.41'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '98.5999984741211',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'IOC',\n",
       "   'prob': '65.23'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '124.8499984741211',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'BEL',\n",
       "   'prob': '66.96'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '1',\n",
       "   'pre_close': '7538.7001953125',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'TATAELXSI',\n",
       "   'prob': '48.12'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '19500.05078125',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'NSEI',\n",
       "   'prob': '84.69'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataa = { \"data\":[]} \n",
    "\n",
    "for res in result:\n",
    "    dataa[\"data\"].append({ \n",
    "            \"cdate\": res[Icdate],\n",
    "            \"result\": str(res[Iresult]),\n",
    "            \"pre_close\" : str(res[Iclose]),            \n",
    "            \"isClassification\": res[IisClassification],\n",
    "            \"model\": res[Imodel],\n",
    "            \"stock\": res[Istock],\n",
    "            \"prob\": str(res[Iprob]),\n",
    "    })\n",
    "    \n",
    "dataa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://website-development-kerala.com/api_214124524/ai_model_daily_runner.php\"\n",
    "\n",
    "response = requests.post(url, json=dataa)\n",
    "print(response.status_code)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OLECTRA.NS': Date\n",
       " 2005-05-06    1.0\n",
       " 2005-05-10    0.0\n",
       " 2005-05-12    0.0\n",
       " 2005-05-13    1.0\n",
       " 2005-05-16    1.0\n",
       "              ... \n",
       " 2023-06-27    0.0\n",
       " 2023-06-28    1.0\n",
       " 2023-06-30    0.0\n",
       " 2023-07-03    0.0\n",
       " 2023-07-05    0.0\n",
       " Name: TARGET, Length: 1818, dtype: float64,\n",
       " 'LT.NS': Date\n",
       " 2005-05-19    0.0\n",
       " 2005-05-20    0.0\n",
       " 2005-05-23    0.0\n",
       " 2005-05-26    0.0\n",
       " 2005-06-01    0.0\n",
       "              ... \n",
       " 2023-06-22    0.0\n",
       " 2023-06-27    0.0\n",
       " 2023-06-28    1.0\n",
       " 2023-06-30    0.0\n",
       " 2023-07-04    1.0\n",
       " Name: TARGET, Length: 2289, dtype: float64,\n",
       " 'CONCOR.NS': Date\n",
       " 2005-05-12    0.0\n",
       " 2005-05-13    0.0\n",
       " 2005-05-16    0.0\n",
       " 2005-05-18    0.0\n",
       " 2005-05-19    0.0\n",
       "              ... \n",
       " 2023-06-23    0.0\n",
       " 2023-06-26    0.0\n",
       " 2023-06-28    1.0\n",
       " 2023-06-30    1.0\n",
       " 2023-07-05    1.0\n",
       " Name: TARGET, Length: 2225, dtype: float64,\n",
       " 'ELGIEQUIP.NS': Date\n",
       " 2005-05-18    1.0\n",
       " 2005-05-20    1.0\n",
       " 2005-05-23    1.0\n",
       " 2005-05-25    1.0\n",
       " 2005-05-26    1.0\n",
       "              ... \n",
       " 2023-06-14    1.0\n",
       " 2023-06-16    0.0\n",
       " 2023-06-21    0.0\n",
       " 2023-06-23    0.0\n",
       " 2023-06-26    0.0\n",
       " Name: TARGET, Length: 2022, dtype: float64,\n",
       " 'IOC.NS': Date\n",
       " 2005-05-23    0.0\n",
       " 2005-05-25    0.0\n",
       " 2005-05-27    0.0\n",
       " 2005-05-30    0.0\n",
       " 2005-06-02    1.0\n",
       "              ... \n",
       " 2023-06-26    0.0\n",
       " 2023-06-28    1.0\n",
       " 2023-06-30    1.0\n",
       " 2023-07-03    0.0\n",
       " 2023-07-05    0.0\n",
       " Name: TARGET, Length: 2170, dtype: float64,\n",
       " 'BEL.NS': Date\n",
       " 2005-05-11    1.0\n",
       " 2005-05-12    0.0\n",
       " 2005-05-16    0.0\n",
       " 2005-05-17    0.0\n",
       " 2005-05-18    1.0\n",
       "              ... \n",
       " 2023-06-22    0.0\n",
       " 2023-06-26    0.0\n",
       " 2023-06-28    1.0\n",
       " 2023-06-30    0.0\n",
       " 2023-07-05    0.0\n",
       " Name: TARGET, Length: 2253, dtype: float64,\n",
       " 'TATAELXSI.NS': Date\n",
       " 2005-05-12    0.0\n",
       " 2005-05-20    0.0\n",
       " 2005-05-23    0.0\n",
       " 2005-05-25    0.0\n",
       " 2005-05-26    0.0\n",
       "              ... \n",
       " 2023-06-20    1.0\n",
       " 2023-06-21    0.0\n",
       " 2023-06-26    0.0\n",
       " 2023-06-28    1.0\n",
       " 2023-07-05    1.0\n",
       " Name: TARGET, Length: 2228, dtype: float64,\n",
       " '^NSEI': Date\n",
       " 2013-04-29    1.0\n",
       " 2013-05-02    1.0\n",
       " 2013-05-06    1.0\n",
       " 2013-05-07    0.0\n",
       " 2013-05-08    1.0\n",
       "              ... \n",
       " 2023-06-27    0.0\n",
       " 2023-06-28    0.0\n",
       " 2023-06-30    0.0\n",
       " 2023-07-03    0.0\n",
       " 2023-07-05    0.0\n",
       " Name: TARGET, Length: 1353, dtype: float64}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=6, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=0.5, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.7, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=115, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=6, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=12, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=80, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=12, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.7, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=6, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=80, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=25, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for symbol in symbols:\n",
    "    retrained_model = loaded_models[symbol].fit(finaldata[symbol],final_target[symbol])\n",
    "    print(retrained_model)\n",
    "    with open('../TrainedModel/xg/{}_model_2.pkl'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(retrained_model, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
