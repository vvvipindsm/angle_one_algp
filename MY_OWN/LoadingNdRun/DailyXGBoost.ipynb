{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from dataProcessing import DataProcessing\n",
    "# Remove Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_setup_data(sybmol,input_data):\n",
    "    df = pd.read_csv(\"../stock_historical_data/{}.csv\".format(sybmol))\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    new_data = pd.DataFrame(input_data)\n",
    "    new_data.set_index(\"Date\", inplace=True)\n",
    "    concatenated_df = pd.concat([df,new_data])\n",
    "    return concatenated_df\n",
    "\n",
    "def fetch_stock_data(tickers):\n",
    "    data = yfinance.download(tickers,period='1d')\n",
    "    print(data)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "           Adj Close                Close                     High  \\\n",
      "              IOC.NS TATAMOTORS.NS IOC.NS TATAMOTORS.NS     IOC.NS   \n",
      "Date                                                                 \n",
      "2023-07-05      95.5        588.25   95.5        588.25  95.699997   \n",
      "\n",
      "                                Low                     Open                \\\n",
      "           TATAMOTORS.NS     IOC.NS TATAMOTORS.NS     IOC.NS TATAMOTORS.NS   \n",
      "Date                                                                         \n",
      "2023-07-05         593.0  93.400002    584.950012  95.150002         592.0   \n",
      "\n",
      "              Volume                \n",
      "              IOC.NS TATAMOTORS.NS  \n",
      "Date                                \n",
      "2023-07-05  14283796       8715919  \n",
      "           Adj Close                Close                     High  \\\n",
      "              IOC.NS TATAMOTORS.NS IOC.NS TATAMOTORS.NS     IOC.NS   \n",
      "Date                                                                 \n",
      "2023-07-05      95.5        588.25   95.5        588.25  95.699997   \n",
      "\n",
      "                                Low                     Open                \\\n",
      "           TATAMOTORS.NS     IOC.NS TATAMOTORS.NS     IOC.NS TATAMOTORS.NS   \n",
      "Date                                                                         \n",
      "2023-07-05         593.0  93.400002    584.950012  95.150002         592.0   \n",
      "\n",
      "              Volume                \n",
      "              IOC.NS TATAMOTORS.NS  \n",
      "Date                                \n",
      "2023-07-05  14283796       8715919  \n",
      "{'Open': [592.0], 'Close': [588.25], 'High': [593.0], 'Low': [584.9500122070312], 'Volume': [8715919], 'Date': ['2023-07-05']}\n",
      "{'Open': [95.1500015258789], 'Close': [95.5], 'High': [95.69999694824219], 'Low': [93.4000015258789], 'Volume': [14283796], 'Date': ['2023-07-05']}\n"
     ]
    }
   ],
   "source": [
    "symbols = [\"TATAMOTORS.NS\",\"IOC.NS\"]\n",
    "Icdate = 0\n",
    "Iresult = 1\n",
    "IisClassification = 2\n",
    "Imodel = 3\n",
    "Istock = 4\n",
    "Iclose = 5\n",
    "Iprob = 6\n",
    "  # Add the tickers you want to fetch data for\n",
    "loaded_models = {}\n",
    "result = []\n",
    "\n",
    "final_result = {}\n",
    "final_target = {}\n",
    "stock_data = fetch_stock_data(symbols)\n",
    "print(stock_data)\n",
    "finaldata = {}\n",
    "stock_name = \"TATAMOTORS\"\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "\n",
    "for symbol in symbols:\n",
    "    stock_name = symbol\n",
    "    if symbol == \"^NSEI\":\n",
    "        stock_name = \"NSEI\"\n",
    " \n",
    "    input_data = {\n",
    "                    # \"Open\" : stock_data.head(1).Open[ticker].values[0],\n",
    "                    \"Open\" : [stock_data.head(1).Open[symbol].values[0]],\n",
    "                    \"Close\" : [stock_data.head(1).Close[symbol].values[0]],\n",
    "                    \"High\" : [stock_data.head(1).High[symbol].values[0]],\n",
    "                    \"Low\" : [stock_data.head(1).Low[symbol].values[0]], \n",
    "                    \"Volume\" : [stock_data.head(1).Volume[symbol].values[0]],\n",
    "                    \"Date\":[np.datetime_as_string(stock_data.index, unit='D')[0]]\n",
    "    }\n",
    "    print(input_data)\n",
    "    data = load_and_setup_data(symbol,input_data)\n",
    "    data.to_csv(f\"../stock_historical_data/{symbol}.csv\")\n",
    "    data = DataProcessing(symbol,data)\n",
    "    # Specify Target\n",
    "    data.df.loc[data.df[\"Range\"].shift(-1) > data.df[\"Avg_Range\"], \"TARGET\"] = 1\n",
    "    data.df.loc[data.df[\"Range\"].shift(-1) <= data.df[\"Avg_Range\"], \"TARGET\"] = 0\n",
    "    loaded_model = {}\n",
    "    feature_item = {}\n",
    "    with open('../TrainedModel/xg/{}_model_2.pkl'.format(symbol), 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    with open('../TrainedModel/xg/{}_features.txt'.format(symbol), 'rb') as f:\n",
    "        feature_item = pickle.load(f)\n",
    "    #final training\n",
    "    loaded_models[symbol] = loaded_model\n",
    "    data.df = data.df.dropna()\n",
    "\n",
    "    final_target[symbol] = data.df[\"TARGET\"]\n",
    "    df = data.df[feature_item]\n",
    "    finaldata[symbol]= df \n",
    "    stock_name_only = stock_name.replace(\".NS\",\"\")\n",
    "    train_yhat = loaded_model.predict(df[-1:])\n",
    "    train_yhat_proba = loaded_model.predict_proba(df[-1:])\n",
    "    greater = 0\n",
    "    one = train_yhat_proba[0][0]\n",
    "    two = train_yhat_proba[0][1]\n",
    "    if one > two:\n",
    "        greater = one*100\n",
    "    else:\n",
    "        greater = one*100\n",
    "#    print(greater)\n",
    "    final_result[symbol] = [current_date,train_yhat[0],1,'xg',stock_name_only,stock_data.head(1).Close[symbol].values[0],round(greater,2)]\n",
    "    result.append([current_date,train_yhat[0],1,'xg',stock_name_only,stock_data.head(1).Close[symbol].values[0],round(greater,2)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '588.25',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'TATAMOTORS',\n",
       "   'prob': '70.47'},\n",
       "  {'cdate': '06-07-2023',\n",
       "   'result': '0',\n",
       "   'pre_close': '95.5',\n",
       "   'isClassification': 1,\n",
       "   'model': 'xg',\n",
       "   'stock': 'IOC',\n",
       "   'prob': '59.12'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataa = { \"data\":[]} \n",
    "\n",
    "for res in result:\n",
    "    dataa[\"data\"].append({ \n",
    "            \"cdate\": res[Icdate],\n",
    "            \"result\": str(res[Iresult]),\n",
    "            \"pre_close\" : str(res[Iclose]),            \n",
    "            \"isClassification\": res[IisClassification],\n",
    "            \"model\": res[Imodel],\n",
    "            \"stock\": res[Istock],\n",
    "            \"prob\": str(res[Iprob]),\n",
    "    })\n",
    "    \n",
    "dataa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://website-development-kerala.com/api_214124524/ai_model_daily_runner.php\"\n",
    "\n",
    "response = requests.post(url, json=dataa)\n",
    "print(response.status_code)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TATAMOTORS.NS': Date\n",
       " 2005-02-16    1.0\n",
       " 2005-02-17    1.0\n",
       " 2005-02-18    0.0\n",
       " 2005-02-21    0.0\n",
       " 2005-02-22    0.0\n",
       "              ... \n",
       " 2023-07-05    0.0\n",
       " 2023-07-05    0.0\n",
       " 2023-07-05    0.0\n",
       " 2023-07-05    0.0\n",
       " 2023-07-05    0.0\n",
       " Name: TARGET, Length: 4582, dtype: float64,\n",
       " 'IOC.NS': Date\n",
       " 2005-02-16    0.0\n",
       " 2005-02-17    0.0\n",
       " 2005-02-18    0.0\n",
       " 2005-02-21    0.0\n",
       " 2005-02-22    0.0\n",
       "              ... \n",
       " 2023-07-05    1.0\n",
       " 2023-07-05    1.0\n",
       " 2023-07-05    1.0\n",
       " 2023-07-05    1.0\n",
       " 2023-07-05    1.0\n",
       " Name: TARGET, Length: 4560, dtype: float64}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=12, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=80, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
      "              gamma=12, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=80, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n"
     ]
    }
   ],
   "source": [
    "for symbol in symbols:\n",
    "    retrained_model = loaded_models[symbol].fit(finaldata[symbol],final_target[symbol])\n",
    "    print(retrained_model)\n",
    "    with open('../TrainedModel/xg/{}_model_2.pkl'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(retrained_model, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
