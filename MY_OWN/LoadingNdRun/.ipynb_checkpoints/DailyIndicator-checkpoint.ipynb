{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from ta import add_all_ta_features\n",
    "\n",
    "from dataProcessing import DataProcessing\n",
    "# Remove Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_setup_data(sybmol):\n",
    "    df = pd.read_csv(\"../stock_historical_data/{}.csv\".format(sybmol))\n",
    "  #  df.set_index(\"Date\", inplace=True)\n",
    "   # new_data = pd.DataFrame(input_data)\n",
    "   # new_data.set_index(\"Date\", inplace=True)\n",
    "    #concatenated_df = pd.concat([df,new_data])\n",
    "    return df\n",
    "\n",
    "def fetch_stock_data(tickers):\n",
    "    data = yfinance.download(tickers,period='1d')\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  16 of 16 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.550213708854585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.347914136726374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.303653618305205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:780: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/ta/trend.py:785: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:956: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Low', 'Close'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m     df_stationary\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mna_list, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m#print(feature_item)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#print(\"point one :\" ,len(df_stationary.columns))\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     df_stationary \u001b[38;5;241m=\u001b[39m \u001b[43mdf_stationary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_item\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m#print(\"point two :\" ,len(df_stationary.columns))\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#    print(df_stationary)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     df_stationary \u001b[38;5;241m=\u001b[39m df_stationary\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/pandas/core/indexes/base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Low', 'Close'] not in index\""
     ]
    }
   ],
   "source": [
    "#symbols = [\"CONCOR.NS\",\"ELGIEQUIP.NS\"]\n",
    "symbols = [\"OLECTRA.NS\",\"CONCOR.NS\",\"ELGIEQUIP.NS\",\"IOC.NS\",\"BEL.NS\",\"TATAELXSI.NS\",\"^NSEI\",\"HDFCBANK.NS\",\"TATAMOTORS.NS\",\"SBIN.NS\",\"TCS.NS\",\"TITAN.NS\",\"SUNPHARMA.BO\",\"TECHM.NS\", \"ASIANPAINT.NS\",\"TATACONSUM.NS\"]\n",
    "\n",
    "#symbols = [\"^NSEI\",\"BEL.NS\"]\n",
    "\n",
    "Icdate = 0\n",
    "Iresult = 1\n",
    "IisClassification = 2\n",
    "Imodel = 3\n",
    "Istock = 4\n",
    "Iclose = 5\n",
    "Iprob = 6\n",
    "  # Add the tickers you want to fetch data for\n",
    "loaded_models = {}\n",
    "result = []\n",
    "\n",
    "final_result = {}\n",
    "final_target = {}\n",
    "stock_data = fetch_stock_data(symbols)\n",
    "#print(stock_data)\n",
    "finaldata = {}\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "\n",
    "for symbol in symbols:\n",
    "    stock_name = symbol\n",
    "    print(stock_name)\n",
    "    if symbol == \"^NSEI\":\n",
    "        stock_name = \"NSEI\"\n",
    " \n",
    "    data = load_and_setup_data(symbol)\n",
    "    data = data[[\"Open\", \"High\", \"Low\", \"Close\",\"Volume\"]]\n",
    "    data['weekday'] =pd.to_datetime(data.index).dayofweek\n",
    "   # data.to_csv(f\"../stock_historical_data/{symbol}.csv\")\n",
    "    data = add_all_ta_features(data, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
    " \n",
    "    # Find NaN Rows\n",
    "    #na_list = data.columns[data.isna().any().tolist()]\n",
    "   # data.drop(columns=na_list, inplace=True)\n",
    "    # Handle inf values\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.dropna(axis=1, inplace=True)\n",
    "    #data = data.drop(['volatility_kchi','volatility_kcli'], axis=1)\n",
    "\n",
    "    #df_stationary.head()\n",
    "   # print(data)\n",
    "    non_stationaries = []\n",
    "    for col in data.columns:\n",
    "        if col != \"volatility_kchi\" and col != \"volatility_kcli\" and col != \"weekday\":\n",
    "            #print(col)\n",
    "            dftest = adfuller(data[col].values)\n",
    "            p_value = dftest[1]\n",
    "            t_test = dftest[0] < dftest[4][\"1%\"]\n",
    "            if p_value > 0.05 or not t_test:\n",
    "                non_stationaries.append(col)\n",
    "    \n",
    "    df_stationary = data.copy()\n",
    "    \n",
    " \n",
    "  \n",
    "    loaded_model = {}\n",
    "    feature_item = {}\n",
    "    with open('../TrainedModel/indicator/{}_model_2.pkl'.format(symbol), 'rb') as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "    with open('../TrainedModel/indicator/{}_features.txt'.format(symbol), 'rb') as f:\n",
    "        feature_item = pickle.load(f)\n",
    "   # print(feature_item,symbol,len(feature_item))\n",
    "    #print(\"point zero :\" ,len(df_stationary.columns))\n",
    "\n",
    "    df_stationary[non_stationaries] = df_stationary[non_stationaries].pct_change()\n",
    "    df_stationary = df_stationary.iloc[1:]\n",
    "    # Find NaN Rows\n",
    "    na_list = df_stationary.columns[df_stationary.isna().any().tolist()]\n",
    "    \n",
    "    df_stationary.drop(columns=na_list, inplace=True)\n",
    "    #print(feature_item)\n",
    "    #print(\"point one :\" ,len(df_stationary.columns))\n",
    "    df_stationary = df_stationary[feature_item]\n",
    "    #print(\"point two :\" ,len(df_stationary.columns))\n",
    "\n",
    "#    print(df_stationary)\n",
    "    df_stationary = df_stationary.iloc[1:]\n",
    "    \n",
    "    df_stationary[np.isinf(df_stationary)] = np.nan  # Replace inf with NaN\n",
    "    df_stationary = df_stationary.dropna()\n",
    "    #print(\"point three\",len(df_stationary.columns),symbol)\n",
    "    has_inf = \"no inf data\"\n",
    "    if np.isinf(df_stationary).any().any():\n",
    "        has_inf = \"has inf data\"\n",
    "    df_stationary.replace(np.inf, np.nan, inplace=True)\n",
    "    df_stationary.dropna(inplace=True)\n",
    "\n",
    "        \n",
    "    #print(\"check infifty value in\",has_inf)\n",
    "   # print(symbol,\" :\",len(df_stationary.columns),len(feature_item))\n",
    "    finaldata[symbol] = df_stationary \n",
    "    df_stationary = StandardScaler().fit_transform(df_stationary)\n",
    "    y_pred = loaded_model.predict(df_stationary)\n",
    "    y_pred = loaded_model.predict(df_stationary)\n",
    "\n",
    "    #print(\"got result\",symbol)\n",
    "    # Specify Target\n",
    "\n",
    "    #final training\n",
    "    loaded_models[symbol] = loaded_model\n",
    "    stock_name_only = stock_name.replace(\".NS\",\"\")\n",
    "   \n",
    "    train_yhat = loaded_model.predict(df_stationary[-1:])\n",
    "    train_yhat_proba = loaded_model.predict_proba(df_stationary[-1:])\n",
    "    greater = 0\n",
    "    one = train_yhat_proba[0][0]\n",
    "    two = train_yhat_proba[0][1]\n",
    "    if one > two:\n",
    "        greater = one*100\n",
    "    else:\n",
    "        greater = one*100\n",
    "    print(greater)\n",
    "    final_result[symbol] = [current_date,train_yhat[0],1,'indicator',stock_name_only,stock_data.head(1).Close[symbol].values[0],round(greater,2)]\n",
    "    result.append([current_date,train_yhat[0],1,'indicator',stock_name_only,stock_data.head(1).Close[symbol].values[0],round(greater,2)])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '1373.6500244140625',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'OLECTRA',\n",
       "   'prob': '60.87'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '1',\n",
       "   'pre_close': '688.7999877929688',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'CONCOR',\n",
       "   'prob': '42.58'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '572.9500122070312',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'ELGIEQUIP',\n",
       "   'prob': '58.31'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '96.5999984741211',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'IOC',\n",
       "   'prob': '52.06'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '127.1500015258789',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'BEL',\n",
       "   'prob': '52.93'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '7730.75',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'TATAELXSI',\n",
       "   'prob': '50.77'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '1',\n",
       "   'pre_close': '19564.5',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'NSEI',\n",
       "   'prob': '42.68'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '4.349999904632568',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'RELI',\n",
       "   'prob': '71.69'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '1644.5',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'HDFCBANK',\n",
       "   'prob': '65.55'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '624.9000244140625',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'TATAMOTORS',\n",
       "   'prob': '61.66'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '1',\n",
       "   'pre_close': '584.4000244140625',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'SBIN',\n",
       "   'prob': '38.92'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '3514.64990234375',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'TCS',\n",
       "   'prob': '81.18'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '1',\n",
       "   'pre_close': '3055.550048828125',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'TITAN',\n",
       "   'prob': '21.89'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '1072.4000244140625',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'SUNPHARMA.BO',\n",
       "   'prob': '87.02'},\n",
       "  {'cdate': '15-07-2023',\n",
       "   'result': '-1',\n",
       "   'pre_close': '1228.6500244140625',\n",
       "   'isClassification': 1,\n",
       "   'model': 'indicator',\n",
       "   'stock': 'TECHM',\n",
       "   'prob': '85.49'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataa = { \"data\":[]} \n",
    "\n",
    "for res in result:\n",
    "    dataa[\"data\"].append({ \n",
    "            \"cdate\": res[Icdate],\n",
    "            \"result\": str(res[Iresult]),\n",
    "            \"pre_close\" : str(res[Iclose]),            \n",
    "            \"isClassification\": res[IisClassification],\n",
    "            \"model\": res[Imodel],\n",
    "            \"stock\": res[Istock],\n",
    "            \"prob\": str(res[Iprob]),\n",
    "    })\n",
    "    \n",
    "dataa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://website-development-kerala.com/api_214124524/ai_model_daily_runner.php\"\n",
    "\n",
    "response = requests.post(url, json=dataa)\n",
    "print(response.status_code)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbols:\n",
    "  \n",
    "    # Set Target (for Supervised ML later on)\n",
    "    finaldata[symbol][\"TARGET\"] = -1\n",
    "    finaldata[symbol].loc[finaldata[symbol][\"Close\"].shift(-1) > finaldata[symbol][\"Close\"], \"TARGET\"] = 1\n",
    "    finaldata[symbol].dropna(inplace=True)\n",
    "    #print(finaldata)\n",
    "    df_tar = finaldata[symbol][[\"TARGET\"]]\n",
    "    df_stationar = StandardScaler().fit_transform(finaldata[symbol].iloc[:, :-1])\n",
    "   # print(df_tar)\n",
    "\n",
    "    retrained_model = loaded_models[symbol].fit(df_stationar,df_tar)\n",
    "    print(df_stationar)\n",
    "    with open('../TrainedModel/indicator/{}_model_2.pkl'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(retrained_model, f)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
