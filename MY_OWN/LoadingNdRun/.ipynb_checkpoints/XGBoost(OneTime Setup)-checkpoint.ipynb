{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data Find Future list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from dataProcessing import DataProcessing\n",
    "# Remove Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findFeature = False\n",
    "features = ['Range', 'RSI', 'RSI_Ret', 'Avg_Range','TARGET']\n",
    "symbol = \"TATAMOTORS.NS\"\n",
    "stock_name = \"TATAMOTORS\"\n",
    "df = pd.read_csv(\"../stock_historical_data/{}.csv\".format(symbol))\n",
    "df.set_index(\"Date\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dataProcessing.DataProcessing object at 0x7fd5820524c0>\n"
     ]
    }
   ],
   "source": [
    "#strat_mgr = StrategyManager(symbol, \"\", \"\",concatenated_df)\n",
    "data = DataProcessing(\"TATAMOTORS\",df)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = data.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Target\n",
    "df_f.loc[df_f[\"Range\"].shift(-1) > df_f[\"Avg_Range\"], \"TARGET\"] = 1\n",
    "df_f.loc[df_f[\"Range\"].shift(-1) <= df_f[\"Avg_Range\"], \"TARGET\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>Bench_C_Rets</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>123297.453428</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>287.190476</td>\n",
       "      <td>4.150620</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>123089.530235</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>310.714286</td>\n",
       "      <td>4.158596</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>122881.957672</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>334.238095</td>\n",
       "      <td>4.157242</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>122674.735146</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>357.761905</td>\n",
       "      <td>4.989899</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>122467.862068</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>381.285714</td>\n",
       "      <td>4.989899</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High  Low  Close  Volume  Returns     Range   Bench_C_Rets  \\\n",
       "Date                                                                           \n",
       "2023-07-05   0.0   0.0  0.0  593.0     0.0      0.0  0.013762  123297.453428   \n",
       "2023-07-05   0.0   0.0  0.0  593.0     0.0      0.0  0.013762  123089.530235   \n",
       "2023-07-05   0.0   0.0  0.0  593.0     0.0      0.0  0.013762  122881.957672   \n",
       "2023-07-05   0.0   0.0  0.0  593.0     0.0      0.0  0.013762  122674.735146   \n",
       "2023-07-05   0.0   0.0  0.0  593.0     0.0      0.0  0.013762  122467.862068   \n",
       "\n",
       "                  RSI  RSI_Ret  ...       MA_21  Roll_Rets  Avg_Range  \\\n",
       "Date                            ...                                     \n",
       "2023-07-05  81.102302      1.0  ...  287.190476   4.150620   0.018151   \n",
       "2023-07-05  81.102302      1.0  ...  310.714286   4.158596   0.017915   \n",
       "2023-07-05  81.102302      1.0  ...  334.238095   4.157242   0.018193   \n",
       "2023-07-05  81.102302      1.0  ...  357.761905   4.989899   0.017971   \n",
       "2023-07-05  81.102302      1.0  ...  381.285714   4.989899   0.017750   \n",
       "\n",
       "            Returns_T1  Range_T1  RSI_Ret_T1  Returns_T2  Range_T2  \\\n",
       "Date                                                                 \n",
       "2023-07-05         0.0  0.013762         1.0         0.0  0.013762   \n",
       "2023-07-05         0.0  0.013762         1.0         0.0  0.013762   \n",
       "2023-07-05         0.0  0.013762         1.0         0.0  0.013762   \n",
       "2023-07-05         0.0  0.013762         1.0         0.0  0.013762   \n",
       "2023-07-05         0.0  0.013762         1.0         0.0  0.013762   \n",
       "\n",
       "            RSI_Ret_T2  TARGET  \n",
       "Date                            \n",
       "2023-07-05         1.0     0.0  \n",
       "2023-07-05         1.0     0.0  \n",
       "2023-07-05         1.0     0.0  \n",
       "2023-07-05         1.0     0.0  \n",
       "2023-07-05         1.0     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "nan_location = np.where(np.isnan(df_f))\n",
    "nan_location\n",
    "# Fill NA\n",
    "df_f[\"TARGET\"].fillna(0, inplace=True)\n",
    "df_f.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame does not contain NaN values\n"
     ]
    }
   ],
   "source": [
    "# Remove unwanted columns\n",
    "df_tts = df_f.copy()\n",
    "df_tts.drop(columns=[\"Close\", \"Bench_C_Rets\", \"Open\", \"High\", \"Low\"], inplace=True)\n",
    "# Find columns with infinite values\n",
    "columns_with_inf = df_tts.columns[np.isinf(df_tts).any()]\n",
    "\n",
    "#Drop columns with infinite values\n",
    "df_tts.drop(columns_with_inf, axis=1, inplace=True)\n",
    "has_inf = np.isinf(df_tts.values).any()\n",
    "\n",
    "if has_inf:\n",
    "    print(\"DataFrame contains NaN values\",columns_with_inf)\n",
    "else:\n",
    "    print(\"DataFrame does not contain NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>MA_12</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-02-16</th>\n",
       "      <td>-0.030933</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>47.715626</td>\n",
       "      <td>0.811499</td>\n",
       "      <td>79.790535</td>\n",
       "      <td>78.437493</td>\n",
       "      <td>-0.051231</td>\n",
       "      <td>0.032276</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.989009</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>1.041721</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-17</th>\n",
       "      <td>-0.006608</td>\n",
       "      <td>0.188465</td>\n",
       "      <td>45.791272</td>\n",
       "      <td>0.959670</td>\n",
       "      <td>79.735636</td>\n",
       "      <td>78.558002</td>\n",
       "      <td>-0.056590</td>\n",
       "      <td>0.038046</td>\n",
       "      <td>-0.030933</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.811499</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>0.989009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-18</th>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.073304</td>\n",
       "      <td>40.393484</td>\n",
       "      <td>0.882122</td>\n",
       "      <td>79.642576</td>\n",
       "      <td>78.637576</td>\n",
       "      <td>-0.046083</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>-0.006608</td>\n",
       "      <td>0.188465</td>\n",
       "      <td>0.959670</td>\n",
       "      <td>-0.030933</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.811499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-21</th>\n",
       "      <td>-0.003343</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>39.589380</td>\n",
       "      <td>0.980093</td>\n",
       "      <td>79.425661</td>\n",
       "      <td>78.758085</td>\n",
       "      <td>-0.028580</td>\n",
       "      <td>0.037256</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.073304</td>\n",
       "      <td>0.882122</td>\n",
       "      <td>-0.006608</td>\n",
       "      <td>0.188465</td>\n",
       "      <td>0.959670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-22</th>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>44.291938</td>\n",
       "      <td>1.118783</td>\n",
       "      <td>79.329255</td>\n",
       "      <td>78.840337</td>\n",
       "      <td>-0.014460</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>-0.003343</td>\n",
       "      <td>0.026261</td>\n",
       "      <td>0.980093</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.073304</td>\n",
       "      <td>0.882122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>428.333333</td>\n",
       "      <td>287.190476</td>\n",
       "      <td>4.150620</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>469.500000</td>\n",
       "      <td>310.714286</td>\n",
       "      <td>4.158596</td>\n",
       "      <td>0.017915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>510.666667</td>\n",
       "      <td>334.238095</td>\n",
       "      <td>4.157242</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>551.833333</td>\n",
       "      <td>357.761905</td>\n",
       "      <td>4.989899</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>81.102302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>593.000000</td>\n",
       "      <td>381.285714</td>\n",
       "      <td>4.989899</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4569 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Returns     Range        RSI   RSI_Ret       MA_12       MA_21  \\\n",
       "Date                                                                          \n",
       "2005-02-16 -0.030933  0.042945  47.715626  0.811499   79.790535   78.437493   \n",
       "2005-02-17 -0.006608  0.188465  45.791272  0.959670   79.735636   78.558002   \n",
       "2005-02-18 -0.020466  0.073304  40.393484  0.882122   79.642576   78.637576   \n",
       "2005-02-21 -0.003343  0.026261  39.589380  0.980093   79.425661   78.758085   \n",
       "2005-02-22  0.013208  0.017643  44.291938  1.118783   79.329255   78.840337   \n",
       "...              ...       ...        ...       ...         ...         ...   \n",
       "2023-07-05  0.000000  0.013762  81.102302  1.000000  428.333333  287.190476   \n",
       "2023-07-05  0.000000  0.013762  81.102302  1.000000  469.500000  310.714286   \n",
       "2023-07-05  0.000000  0.013762  81.102302  1.000000  510.666667  334.238095   \n",
       "2023-07-05  0.000000  0.013762  81.102302  1.000000  551.833333  357.761905   \n",
       "2023-07-05  0.000000  0.013762  81.102302  1.000000  593.000000  381.285714   \n",
       "\n",
       "            Roll_Rets  Avg_Range  Returns_T1  Range_T1  RSI_Ret_T1  \\\n",
       "Date                                                                 \n",
       "2005-02-16  -0.051231   0.032276   -0.001574  0.022044    0.989009   \n",
       "2005-02-17  -0.056590   0.038046   -0.030933  0.042945    0.811499   \n",
       "2005-02-18  -0.046083   0.037757   -0.006608  0.188465    0.959670   \n",
       "2005-02-21  -0.028580   0.037256   -0.020466  0.073304    0.882122   \n",
       "2005-02-22  -0.014460   0.037049   -0.003343  0.026261    0.980093   \n",
       "...               ...        ...         ...       ...         ...   \n",
       "2023-07-05   4.150620   0.018151    0.000000  0.013762    1.000000   \n",
       "2023-07-05   4.158596   0.017915    0.000000  0.013762    1.000000   \n",
       "2023-07-05   4.157242   0.018193    0.000000  0.013762    1.000000   \n",
       "2023-07-05   4.989899   0.017971    0.000000  0.013762    1.000000   \n",
       "2023-07-05   4.989899   0.017750    0.000000  0.013762    1.000000   \n",
       "\n",
       "            Returns_T2  Range_T2  RSI_Ret_T2  TARGET  \n",
       "Date                                                  \n",
       "2005-02-16    0.008531  0.018471    1.041721     1.0  \n",
       "2005-02-17   -0.001574  0.022044    0.989009     1.0  \n",
       "2005-02-18   -0.030933  0.042945    0.811499     0.0  \n",
       "2005-02-21   -0.006608  0.188465    0.959670     0.0  \n",
       "2005-02-22   -0.020466  0.073304    0.882122     0.0  \n",
       "...                ...       ...         ...     ...  \n",
       "2023-07-05    0.000000  0.013762    1.000000     0.0  \n",
       "2023-07-05    0.000000  0.013762    1.000000     0.0  \n",
       "2023-07-05    0.000000  0.013762    1.000000     0.0  \n",
       "2023-07-05    0.000000  0.013762    1.000000     0.0  \n",
       "2023-07-05    0.000000  0.013762    1.000000     0.0  \n",
       "\n",
       "[4569 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Feature Selection\n",
    "df_tts = df_tts.copy()\n",
    "if findFeature == False:\n",
    "    df_tts = df_tts[features]\n",
    "df_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (3655, 14)\n",
      "Shape of y_train:  (3655,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Params >> ne: 50, lr: 0.05 md: 1 gm: 1\n"
     ]
    }
   ],
   "source": [
    "# Perform Train Test Split\n",
    "# Split into Learning (X) and Target (y) Data\n",
    "X = df_tts.iloc[:, : -1]\n",
    "y = df_tts.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "\n",
    "# Select type of model to optimize for\n",
    "is_binary = True\n",
    "is_optimise_for_precision = True\n",
    "# Determine Objective and Eval Metrics\n",
    "if is_binary:\n",
    "    objective = \"binary:logistic\"\n",
    "    eval_metric = \"logloss\"\n",
    "    eval_metric_list = [\"error\", \"logloss\", eval_metric]\n",
    "else:\n",
    "    objective = \"multi:softmax\"\n",
    "    eval_metric = \"mlogloss\"\n",
    "    eval_metric_list = [\"merror\", \"mlogloss\", eval_metric]\n",
    "# Refine Eval Metric\n",
    "if is_binary and is_optimise_for_precision:\n",
    "    eval_metric = \"aucpr\"\n",
    "    scoring = \"precision\"\n",
    "elif is_binary and not is_optimise_for_precision:\n",
    "    eval_metric = \"auc\"\n",
    "    scoring = \"f1\"\n",
    "else:\n",
    "    scoring = \"accuracy\"\n",
    "# Build First Classifier Model 0\n",
    "classifier_0 = XGBClassifier(\n",
    "    objective=objective,\n",
    "    booster=\"gbtree\",\n",
    "    eval_metric=eval_metric,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "# Provide Gris for Hyperparams\n",
    "param_grid = {\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.5, 1, 1.5, 2, 3, 6, 12, 20],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 8, 12],\n",
    "    \"n_estimators\": [25, 50, 65, 80, 100, 115, 200]\n",
    "}\n",
    "grid_search = RandomizedSearchCV(estimator=classifier_0, param_distributions=param_grid, scoring=scoring)\n",
    "\n",
    "# Perform Random Search for Best Hyper params\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "hyperparams = best_model.best_params_\n",
    "ne = hyperparams[\"n_estimators\"]\n",
    "lr = hyperparams[\"learning_rate\"]\n",
    "md = hyperparams[\"max_depth\"]\n",
    "gm = hyperparams[\"gamma\"]\n",
    "print(\"Recommended Params >>\", f\"ne: {ne},\", f\"lr: {lr}\", f\"md: {md}\", f\"gm: {gm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# Build Classification Model 1\n",
    "classifier_1 = XGBClassifier(\n",
    "    objective=objective,\n",
    "    booster=\"gbtree\",\n",
    "    eval_metric=eval_metric,\n",
    "    n_estimators=ne,\n",
    "    learning_rate=lr,\n",
    "    max_depth=md,\n",
    "    gamma=gm,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=1,\n",
    "    use_label_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
       "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "eval_set = [(X_train, y_train)]\n",
    "classifier_1.set_params(eval_metric=eval_metric_list)  # Example metric: 'error'\n",
    "\n",
    "classifier_1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #eval_metric=eval_metric_list,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Preds: \n",
      " [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for training data\n",
    "train_yhat = classifier_1.predict(X_train)\n",
    "print(\"Training Preds: \\n\", train_yhat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>MA_12</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-04-09</th>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.020531</td>\n",
       "      <td>43.354554</td>\n",
       "      <td>1.016713</td>\n",
       "      <td>109.954487</td>\n",
       "      <td>110.062856</td>\n",
       "      <td>-0.088619</td>\n",
       "      <td>0.042122</td>\n",
       "      <td>-0.003876</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>0.986687</td>\n",
       "      <td>0.031581</td>\n",
       "      <td>0.033781</td>\n",
       "      <td>1.168626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-23</th>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>27.423322</td>\n",
       "      <td>1.132935</td>\n",
       "      <td>184.769407</td>\n",
       "      <td>191.935309</td>\n",
       "      <td>-0.220846</td>\n",
       "      <td>0.028416</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>0.998643</td>\n",
       "      <td>0.005585</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>1.075158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>-0.008046</td>\n",
       "      <td>0.023525</td>\n",
       "      <td>44.225752</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>407.287498</td>\n",
       "      <td>413.011903</td>\n",
       "      <td>-0.047203</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>0.015035</td>\n",
       "      <td>0.986120</td>\n",
       "      <td>0.022761</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>1.180369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>-0.012927</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>35.465719</td>\n",
       "      <td>0.928562</td>\n",
       "      <td>413.491666</td>\n",
       "      <td>417.242856</td>\n",
       "      <td>-0.056161</td>\n",
       "      <td>0.027078</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.980767</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>1.115132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-09</th>\n",
       "      <td>0.040614</td>\n",
       "      <td>0.044039</td>\n",
       "      <td>61.485340</td>\n",
       "      <td>1.126601</td>\n",
       "      <td>141.828247</td>\n",
       "      <td>142.545179</td>\n",
       "      <td>0.160387</td>\n",
       "      <td>0.035471</td>\n",
       "      <td>-0.021752</td>\n",
       "      <td>0.035872</td>\n",
       "      <td>0.908801</td>\n",
       "      <td>0.027385</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>1.093795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-19</th>\n",
       "      <td>-0.018732</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>47.037061</td>\n",
       "      <td>0.903670</td>\n",
       "      <td>403.020833</td>\n",
       "      <td>397.230951</td>\n",
       "      <td>-0.035107</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>-0.016614</td>\n",
       "      <td>0.020861</td>\n",
       "      <td>0.910720</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.016849</td>\n",
       "      <td>1.024023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-29</th>\n",
       "      <td>-0.002713</td>\n",
       "      <td>0.026572</td>\n",
       "      <td>59.467051</td>\n",
       "      <td>0.988674</td>\n",
       "      <td>146.708898</td>\n",
       "      <td>145.704635</td>\n",
       "      <td>0.108350</td>\n",
       "      <td>0.040250</td>\n",
       "      <td>-0.004081</td>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.983933</td>\n",
       "      <td>0.025097</td>\n",
       "      <td>0.043016</td>\n",
       "      <td>1.067959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.014042</td>\n",
       "      <td>32.720776</td>\n",
       "      <td>1.068973</td>\n",
       "      <td>379.233332</td>\n",
       "      <td>400.283334</td>\n",
       "      <td>-0.175287</td>\n",
       "      <td>0.024788</td>\n",
       "      <td>-0.008437</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.961148</td>\n",
       "      <td>-0.012625</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.943111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-09</th>\n",
       "      <td>-0.034647</td>\n",
       "      <td>0.069388</td>\n",
       "      <td>73.209368</td>\n",
       "      <td>0.911303</td>\n",
       "      <td>95.450000</td>\n",
       "      <td>90.621428</td>\n",
       "      <td>0.447420</td>\n",
       "      <td>0.052603</td>\n",
       "      <td>0.042438</td>\n",
       "      <td>0.051169</td>\n",
       "      <td>1.029955</td>\n",
       "      <td>0.124365</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>1.128473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-07-31</th>\n",
       "      <td>-0.029581</td>\n",
       "      <td>0.095541</td>\n",
       "      <td>41.357872</td>\n",
       "      <td>0.930246</td>\n",
       "      <td>73.837655</td>\n",
       "      <td>72.386059</td>\n",
       "      <td>-0.201755</td>\n",
       "      <td>0.059953</td>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>1.182826</td>\n",
       "      <td>-0.070474</td>\n",
       "      <td>0.112532</td>\n",
       "      <td>0.822497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3655 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Returns     Range        RSI   RSI_Ret       MA_12       MA_21  \\\n",
       "Date                                                                          \n",
       "2008-04-09  0.003415  0.020531  43.354554  1.016713  109.954487  110.062856   \n",
       "2011-06-23  0.009723  0.027746  27.423322  1.132935  184.769407  191.935309   \n",
       "2017-12-12 -0.008046  0.023525  44.225752  0.952991  407.287498  413.011903   \n",
       "2017-12-06 -0.012927  0.022785  35.465719  0.928562  413.491666  417.242856   \n",
       "2010-04-09  0.040614  0.044039  61.485340  1.126601  141.828247  142.545179   \n",
       "...              ...       ...        ...       ...         ...         ...   \n",
       "2023-01-19 -0.018732  0.019245  47.037061  0.903670  403.020833  397.230951   \n",
       "2006-12-29 -0.002713  0.026572  59.467051  0.988674  146.708898  145.704635   \n",
       "2017-08-30  0.006381  0.014042  32.720776  1.068973  379.233332  400.283334   \n",
       "2020-06-09 -0.034647  0.069388  73.209368  0.911303   95.450000   90.621428   \n",
       "2008-07-31 -0.029581  0.095541  41.357872  0.930246   73.837655   72.386059   \n",
       "\n",
       "            Roll_Rets  Avg_Range  Returns_T1  Range_T1  RSI_Ret_T1  \\\n",
       "Date                                                                 \n",
       "2008-04-09  -0.088619   0.042122   -0.003876  0.021061    0.986687   \n",
       "2011-06-23  -0.220846   0.028416   -0.000320  0.019626    0.998643   \n",
       "2017-12-12  -0.047203   0.026391   -0.002432  0.015035    0.986120   \n",
       "2017-12-06  -0.056161   0.027078   -0.003468  0.022570    0.980767   \n",
       "2010-04-09   0.160387   0.035471   -0.021752  0.035872    0.908801   \n",
       "...               ...        ...         ...       ...         ...   \n",
       "2023-01-19  -0.035107   0.022259   -0.016614  0.020861    0.910720   \n",
       "2006-12-29   0.108350   0.040250   -0.004081  0.032310    0.983933   \n",
       "2017-08-30  -0.175287   0.024788   -0.008437  0.021098    0.961148   \n",
       "2020-06-09   0.447420   0.052603    0.042438  0.051169    1.029955   \n",
       "2008-07-31  -0.201755   0.059953    0.049073  0.079193    1.182826   \n",
       "\n",
       "            Returns_T2  Range_T2  RSI_Ret_T2  \n",
       "Date                                          \n",
       "2008-04-09    0.031581  0.033781    1.168626  \n",
       "2011-06-23    0.005585  0.021237    1.075158  \n",
       "2017-12-12    0.022761  0.019089    1.180369  \n",
       "2017-12-06    0.011908  0.023774    1.115132  \n",
       "2010-04-09    0.027385  0.030342    1.093795  \n",
       "...                ...       ...         ...  \n",
       "2023-01-19    0.005569  0.016849    1.024023  \n",
       "2006-12-29    0.025097  0.043016    1.067959  \n",
       "2017-08-30   -0.012625  0.024055    0.943111  \n",
       "2020-06-09    0.124365  0.135285    1.128473  \n",
       "2008-07-31   -0.070474  0.112532    0.822497  \n",
       "\n",
       "[3655 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set K-Fold Cross Validation Levels\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "train_results = cross_val_score(classifier_1, X_train, y_train, scoring=scoring, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy K-Fold:  0.63\n",
      "Std Deviation K-Fold:  0.06\n",
      "Precision Score 0:  0.619\n",
      "Precision Score 1:  0.685\n",
      "\n",
      "Just for reference. Right now, we are only focussed on getting some initial features.\n",
      "If the results look too good to be true, they probably are.\n"
     ]
    }
   ],
   "source": [
    "# Brief Review of Training Results\n",
    "print(\"Average Accuracy K-Fold: \", round(train_results.mean(), 2))\n",
    "print(\"Std Deviation K-Fold: \", round(train_results.std(), 2))\n",
    "print(\"Precision Score 0: \", round(precision_score(y_train, train_yhat, average=None)[0], 3))\n",
    "print(\"Precision Score 1: \", round(precision_score(y_train, train_yhat, average=None)[1], 3))\n",
    "print(\"\")\n",
    "print(\"Just for reference. Right now, we are only focussed on getting some initial features.\")\n",
    "print(\"If the results look too good to be true, they probably are.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
       "              gamma=1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=50, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_1.fit(\n",
    "    X,\n",
    "    y,\n",
    "    #eval_metric=eval_metric_list,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Feature Importances\n",
    "fig = plt.figure(figsize=(22, 5))\n",
    "importance_labels = X.columns\n",
    "importance_features = classifier_1.feature_importances_\n",
    "plt.bar(importance_labels, importance_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Features\n",
    "mean_feature_importance = importance_features.mean()\n",
    "i = 0\n",
    "recommended_feature_labels = []\n",
    "recommended_feature_score = []\n",
    "for fi in importance_features:\n",
    "    if fi > mean_feature_importance:\n",
    "        recommended_feature_labels.append(importance_labels[i])\n",
    "        recommended_feature_score.append(fi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Range', 'RSI', 'RSI_Ret', 'Avg_Range']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "if findFeature == False:\n",
    "    with open('../TrainedModel/xg/{}_model_2.pkl'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(classifier_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Range', 'RSI', 'RSI_Ret', 'Avg_Range']\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "if findFeature == True:\n",
    "    print(recommended_feature_labels)\n",
    "    with open('../TrainedModel/xg/{}_features.txt'.format(symbol), 'wb') as f:\n",
    "        pickle.dump(recommended_feature_labels, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
