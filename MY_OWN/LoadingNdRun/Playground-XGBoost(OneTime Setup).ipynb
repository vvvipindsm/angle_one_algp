{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZK36hW6M7cl"
   },
   "source": [
    "#Libraries and Data Find Future list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 2554,
     "status": "ok",
     "timestamp": 1621008666318,
     "user": {
      "displayName": "Diogo Resende",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgH4DE06-yE1oiIzCiaAURCl1Escr4LXXiaSnbSaA=s64",
      "userId": "05706604408624562002"
     },
     "user_tz": -120
    },
    "id": "xBzm1qtYNE6M"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "import yfinance\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from dataProcessing import DataProcessing\n",
    "# Remove Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Reporting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Avg_Range', 'TARGET']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findFeature = True\n",
    "#tickers = [\"OLECTRA.NS\",\"LT.NS\",\"CONCOR.NS\",\"ELGIEQUIP.NS\",\"IOC.NS\",\"BEL.NS\",\"TATAELXSI.NS\",\"^NSEI\"]\n",
    "\n",
    "features = [\"Avg_Range\"]\n",
    "features.append(\"TARGET\")\n",
    "symbol = \"OLECTRA.NS\"\n",
    "df = pd.read_csv(\"../stock_historical_data/{}.csv\".format(symbol))\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dataProcessing.DataProcessing object at 0x7fc7b78636a0>\n"
     ]
    }
   ],
   "source": [
    "#strat_mgr = StrategyManager(symbol, \"\", \"\",concatenated_df)\n",
    "data = DataProcessing(symbol,df)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = data.df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>Bench_C_Rets</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>MA_12</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-02-16</th>\n",
       "      <td>-0.042857</td>\n",
       "      <td>-0.051163</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>9.042957</td>\n",
       "      <td>-0.433400</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>9.981809e-01</td>\n",
       "      <td>65.378780</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>8.482604</td>\n",
       "      <td>7.607568</td>\n",
       "      <td>0.295820</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>-0.024752</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>0.943575</td>\n",
       "      <td>0.057591</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>1.060351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-17</th>\n",
       "      <td>-0.014925</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>-0.015464</td>\n",
       "      <td>8.950209</td>\n",
       "      <td>-0.311111</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>1.049416e+00</td>\n",
       "      <td>63.749663</td>\n",
       "      <td>0.975082</td>\n",
       "      <td>8.656507</td>\n",
       "      <td>7.720191</td>\n",
       "      <td>0.205563</td>\n",
       "      <td>0.110439</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>-0.024752</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>0.943575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-18</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>8.811087</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>1.283029e+00</td>\n",
       "      <td>61.282897</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>8.791764</td>\n",
       "      <td>7.826189</td>\n",
       "      <td>0.227057</td>\n",
       "      <td>0.102919</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>0.975082</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.976270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-21</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.053922</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>8.811087</td>\n",
       "      <td>-0.460504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>1.246981e+00</td>\n",
       "      <td>61.282897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.888377</td>\n",
       "      <td>7.934395</td>\n",
       "      <td>0.233467</td>\n",
       "      <td>0.104258</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>0.975082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-22</th>\n",
       "      <td>-0.130233</td>\n",
       "      <td>-0.106977</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>8.532842</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>-0.031579</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.022283e+00</td>\n",
       "      <td>56.235566</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>8.950209</td>\n",
       "      <td>8.040393</td>\n",
       "      <td>0.169630</td>\n",
       "      <td>0.104557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.961305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>972.200012</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>5.896294e+10</td>\n",
       "      <td>73.741634</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>945.524999</td>\n",
       "      <td>886.095232</td>\n",
       "      <td>0.394590</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.033458</td>\n",
       "      <td>1.031909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>0.020302</td>\n",
       "      <td>-0.007797</td>\n",
       "      <td>-0.001927</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>-0.461784</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>6.052768e+10</td>\n",
       "      <td>75.434648</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>951.662501</td>\n",
       "      <td>896.866661</td>\n",
       "      <td>0.387740</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>989.450012</td>\n",
       "      <td>-0.110993</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>6.074210e+10</td>\n",
       "      <td>75.590193</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>954.591670</td>\n",
       "      <td>907.326186</td>\n",
       "      <td>0.390462</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>1.032224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>-0.006513</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>988.450012</td>\n",
       "      <td>-0.187723</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>6.076973e+10</td>\n",
       "      <td>75.236379</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>959.779170</td>\n",
       "      <td>916.690473</td>\n",
       "      <td>0.386201</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>1.022959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-06</th>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>1044.400024</td>\n",
       "      <td>4.270395</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.093290</td>\n",
       "      <td>6.461529e+10</td>\n",
       "      <td>80.684044</td>\n",
       "      <td>1.072407</td>\n",
       "      <td>966.566671</td>\n",
       "      <td>929.492856</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>1.002062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4538 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low        Close    Volume   Returns  \\\n",
       "Date                                                                        \n",
       "2005-02-16 -0.042857 -0.051163  0.054348     9.042957 -0.433400 -0.010152   \n",
       "2005-02-17 -0.014925 -0.019608 -0.015464     8.950209 -0.311111 -0.010256   \n",
       "2005-02-18  0.010101  0.020000 -0.010471     8.811087  0.010187 -0.015544   \n",
       "2005-02-21  0.075000  0.053922 -0.005291     8.811087 -0.460504  0.000000   \n",
       "2005-02-22 -0.130233 -0.106977 -0.042553     8.532842  0.062305 -0.031579   \n",
       "...              ...       ...       ...          ...       ...       ...   \n",
       "2023-06-30  0.008611  0.057282  0.008086   972.200012       inf  0.020897   \n",
       "2023-07-03  0.020302 -0.007797 -0.001927   988.000000 -0.461784  0.016252   \n",
       "2023-07-04  0.018367  0.008659  0.017586   989.450012 -0.110993  0.001468   \n",
       "2023-07-05 -0.006513 -0.011562  0.001538   988.450012 -0.187723 -0.001011   \n",
       "2023-07-06 -0.001614  0.081325  0.008807  1044.400024  4.270395  0.056604   \n",
       "\n",
       "               Range  Bench_C_Rets        RSI   RSI_Ret       MA_12  \\\n",
       "Date                                                                  \n",
       "2005-02-16  0.051546  9.981809e-01  65.378780  0.976270    8.482604   \n",
       "2005-02-17  0.047120  1.049416e+00  63.749663  0.975082    8.656507   \n",
       "2005-02-18  0.079365  1.283029e+00  61.282897  0.961305    8.791764   \n",
       "2005-02-21  0.143617  1.246981e+00  61.282897  1.000000    8.888377   \n",
       "2005-02-22  0.066667  1.022283e+00  56.235566  0.917639    8.950209   \n",
       "...              ...           ...        ...       ...         ...   \n",
       "2023-06-30  0.048802  5.896294e+10  73.741634  1.032224  945.524999   \n",
       "2023-07-03  0.042634  6.052768e+10  75.434648  1.022959  951.662501   \n",
       "2023-07-04  0.033487  6.074210e+10  75.590193  1.002062  954.591670   \n",
       "2023-07-05  0.019969  6.076973e+10  75.236379  0.995319  959.779170   \n",
       "2023-07-06  0.093290  6.461529e+10  80.684044  1.072407  966.566671   \n",
       "\n",
       "                 MA_21  Roll_Rets  Avg_Range  Returns_T1  Range_T1  \\\n",
       "Date                                                                 \n",
       "2005-02-16    7.607568   0.295820   0.111980   -0.024752  0.168478   \n",
       "2005-02-17    7.720191   0.205563   0.110439   -0.010152  0.051546   \n",
       "2005-02-18    7.826189   0.227057   0.102919   -0.010256  0.047120   \n",
       "2005-02-21    7.934395   0.233467   0.104258   -0.015544  0.079365   \n",
       "2005-02-22    8.040393   0.169630   0.104557    0.000000  0.143617   \n",
       "...                ...        ...        ...         ...       ...   \n",
       "2023-06-30  886.095232   0.394590   0.044682    0.000000  0.000000   \n",
       "2023-07-03  896.866661   0.387740   0.043768    0.020897  0.048802   \n",
       "2023-07-04  907.326186   0.390462   0.043734    0.016252  0.042634   \n",
       "2023-07-05  916.690473   0.386201   0.043440    0.001468  0.033487   \n",
       "2023-07-06  929.492856   0.414600   0.043695   -0.001011  0.019969   \n",
       "\n",
       "            RSI_Ret_T1  Returns_T2  Range_T2  RSI_Ret_T2  \n",
       "Date                                                      \n",
       "2005-02-16    0.943575    0.057591  0.093750    1.060351  \n",
       "2005-02-17    0.976270   -0.024752  0.168478    0.943575  \n",
       "2005-02-18    0.975082   -0.010152  0.051546    0.976270  \n",
       "2005-02-21    0.961305   -0.010256  0.047120    0.975082  \n",
       "2005-02-22    1.000000   -0.015544  0.079365    0.961305  \n",
       "...                ...         ...       ...         ...  \n",
       "2023-06-30    1.000000    0.020249  0.033458    1.031909  \n",
       "2023-07-03    1.032224    0.000000  0.000000    1.000000  \n",
       "2023-07-04    1.022959    0.020897  0.048802    1.032224  \n",
       "2023-07-05    1.002062    0.016252  0.042634    1.022959  \n",
       "2023-07-06    0.995319    0.001468  0.033487    1.002062  \n",
       "\n",
       "[4538 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Target\n",
    "df_f.loc[df_f[\"Range\"].shift(-1) > df_f[\"Avg_Range\"], \"TARGET\"] = 1\n",
    "df_f.loc[df_f[\"Range\"].shift(-1) <= df_f[\"Avg_Range\"], \"TARGET\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>Bench_C_Rets</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>972.200012</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>5.896294e+10</td>\n",
       "      <td>73.741634</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>...</td>\n",
       "      <td>886.095232</td>\n",
       "      <td>0.394590</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.033458</td>\n",
       "      <td>1.031909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>0.020302</td>\n",
       "      <td>-0.007797</td>\n",
       "      <td>-0.001927</td>\n",
       "      <td>988.000000</td>\n",
       "      <td>-0.461784</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>6.052768e+10</td>\n",
       "      <td>75.434648</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>...</td>\n",
       "      <td>896.866661</td>\n",
       "      <td>0.387740</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>0.018367</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>989.450012</td>\n",
       "      <td>-0.110993</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>6.074210e+10</td>\n",
       "      <td>75.590193</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>...</td>\n",
       "      <td>907.326186</td>\n",
       "      <td>0.390462</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>-0.006513</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>988.450012</td>\n",
       "      <td>-0.187723</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>6.076973e+10</td>\n",
       "      <td>75.236379</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>...</td>\n",
       "      <td>916.690473</td>\n",
       "      <td>0.386201</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-06</th>\n",
       "      <td>-0.001614</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>1044.400024</td>\n",
       "      <td>4.270395</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.093290</td>\n",
       "      <td>6.461529e+10</td>\n",
       "      <td>80.684044</td>\n",
       "      <td>1.072407</td>\n",
       "      <td>...</td>\n",
       "      <td>929.492856</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low        Close    Volume   Returns  \\\n",
       "Date                                                                        \n",
       "2023-06-30  0.008611  0.057282  0.008086   972.200012       inf  0.020897   \n",
       "2023-07-03  0.020302 -0.007797 -0.001927   988.000000 -0.461784  0.016252   \n",
       "2023-07-04  0.018367  0.008659  0.017586   989.450012 -0.110993  0.001468   \n",
       "2023-07-05 -0.006513 -0.011562  0.001538   988.450012 -0.187723 -0.001011   \n",
       "2023-07-06 -0.001614  0.081325  0.008807  1044.400024  4.270395  0.056604   \n",
       "\n",
       "               Range  Bench_C_Rets        RSI   RSI_Ret  ...       MA_21  \\\n",
       "Date                                                     ...               \n",
       "2023-06-30  0.048802  5.896294e+10  73.741634  1.032224  ...  886.095232   \n",
       "2023-07-03  0.042634  6.052768e+10  75.434648  1.022959  ...  896.866661   \n",
       "2023-07-04  0.033487  6.074210e+10  75.590193  1.002062  ...  907.326186   \n",
       "2023-07-05  0.019969  6.076973e+10  75.236379  0.995319  ...  916.690473   \n",
       "2023-07-06  0.093290  6.461529e+10  80.684044  1.072407  ...  929.492856   \n",
       "\n",
       "            Roll_Rets  Avg_Range  Returns_T1  Range_T1  RSI_Ret_T1  \\\n",
       "Date                                                                 \n",
       "2023-06-30   0.394590   0.044682    0.000000  0.000000    1.000000   \n",
       "2023-07-03   0.387740   0.043768    0.020897  0.048802    1.032224   \n",
       "2023-07-04   0.390462   0.043734    0.016252  0.042634    1.022959   \n",
       "2023-07-05   0.386201   0.043440    0.001468  0.033487    1.002062   \n",
       "2023-07-06   0.414600   0.043695   -0.001011  0.019969    0.995319   \n",
       "\n",
       "            Returns_T2  Range_T2  RSI_Ret_T2  TARGET  \n",
       "Date                                                  \n",
       "2023-06-30    0.020249  0.033458    1.031909     0.0  \n",
       "2023-07-03    0.000000  0.000000    1.000000     0.0  \n",
       "2023-07-04    0.020897  0.048802    1.032224     0.0  \n",
       "2023-07-05    0.016252  0.042634    1.022959     1.0  \n",
       "2023-07-06    0.001468  0.033487    1.002062     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs\n",
    "nan_location = np.where(np.isnan(df_f))\n",
    "nan_location\n",
    "# Fill NA\n",
    "df_f[\"TARGET\"].fillna(0, inplace=True)\n",
    "df_f.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame does not contain NaN values\n"
     ]
    }
   ],
   "source": [
    "# Remove unwanted columns\n",
    "df_tts = df_f.copy()\n",
    "df_tts.drop(columns=[\"Close\", \"Bench_C_Rets\", \"Open\", \"High\", \"Low\"], inplace=True)\n",
    "# Find columns with infinite values\n",
    "columns_with_inf = df_tts.columns[np.isinf(df_tts).any()]\n",
    "\n",
    "#Drop columns with infinite values\n",
    "df_tts.drop(columns_with_inf, axis=1, inplace=True)\n",
    "has_inf = np.isinf(df_tts.values).any()\n",
    "\n",
    "if has_inf:\n",
    "    print(\"DataFrame contains NaN values\",columns_with_inf)\n",
    "else:\n",
    "    print(\"DataFrame does not contain NaN values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stationaries = []\n",
    "for col in df_tts.columns:\n",
    "    if col != \"volatility_kchi\" and col != \"volatility_kcli\":\n",
    "        dftest = adfuller(df_tts[col].values)\n",
    "        p_value = dftest[1]\n",
    "        t_test = dftest[0] < dftest[4][\"1%\"]\n",
    "        if p_value > 0.05 or not t_test:\n",
    "            non_stationaries.append(col)\n",
    "df_stationary = df_tts.copy()\n",
    "df_stationary[non_stationaries] = df_stationary[non_stationaries].pct_change()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary = df_stationary.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary = StandardScaler().fit_transform(df_stationary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>MA_12</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-02-16</th>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>65.378780</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>8.482604</td>\n",
       "      <td>7.607568</td>\n",
       "      <td>0.295820</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>-0.024752</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>0.943575</td>\n",
       "      <td>0.057591</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>1.060351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-17</th>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>63.749663</td>\n",
       "      <td>0.975082</td>\n",
       "      <td>8.656507</td>\n",
       "      <td>7.720191</td>\n",
       "      <td>0.205563</td>\n",
       "      <td>0.110439</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>-0.024752</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>0.943575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-18</th>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>61.282897</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>8.791764</td>\n",
       "      <td>7.826189</td>\n",
       "      <td>0.227057</td>\n",
       "      <td>0.102919</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>0.975082</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.976270</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>61.282897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.888377</td>\n",
       "      <td>7.934395</td>\n",
       "      <td>0.233467</td>\n",
       "      <td>0.104258</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.047120</td>\n",
       "      <td>0.975082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-22</th>\n",
       "      <td>-0.031579</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>56.235566</td>\n",
       "      <td>0.917639</td>\n",
       "      <td>8.950209</td>\n",
       "      <td>8.040393</td>\n",
       "      <td>0.169630</td>\n",
       "      <td>0.104557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.961305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>73.741634</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>945.524999</td>\n",
       "      <td>886.095232</td>\n",
       "      <td>0.394590</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.033458</td>\n",
       "      <td>1.031909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>75.434648</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>951.662501</td>\n",
       "      <td>896.866661</td>\n",
       "      <td>0.387740</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-04</th>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>75.590193</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>954.591670</td>\n",
       "      <td>907.326186</td>\n",
       "      <td>0.390462</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>1.032224</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>75.236379</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>959.779170</td>\n",
       "      <td>916.690473</td>\n",
       "      <td>0.386201</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-06</th>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.093290</td>\n",
       "      <td>80.684044</td>\n",
       "      <td>1.072407</td>\n",
       "      <td>966.566671</td>\n",
       "      <td>929.492856</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>0.019969</td>\n",
       "      <td>0.995319</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>1.002062</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4538 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Returns     Range        RSI   RSI_Ret       MA_12       MA_21  \\\n",
       "Date                                                                          \n",
       "2005-02-16 -0.010152  0.051546  65.378780  0.976270    8.482604    7.607568   \n",
       "2005-02-17 -0.010256  0.047120  63.749663  0.975082    8.656507    7.720191   \n",
       "2005-02-18 -0.015544  0.079365  61.282897  0.961305    8.791764    7.826189   \n",
       "2005-02-21  0.000000  0.143617  61.282897  1.000000    8.888377    7.934395   \n",
       "2005-02-22 -0.031579  0.066667  56.235566  0.917639    8.950209    8.040393   \n",
       "...              ...       ...        ...       ...         ...         ...   \n",
       "2023-06-30  0.020897  0.048802  73.741634  1.032224  945.524999  886.095232   \n",
       "2023-07-03  0.016252  0.042634  75.434648  1.022959  951.662501  896.866661   \n",
       "2023-07-04  0.001468  0.033487  75.590193  1.002062  954.591670  907.326186   \n",
       "2023-07-05 -0.001011  0.019969  75.236379  0.995319  959.779170  916.690473   \n",
       "2023-07-06  0.056604  0.093290  80.684044  1.072407  966.566671  929.492856   \n",
       "\n",
       "            Roll_Rets  Avg_Range  Returns_T1  Range_T1  RSI_Ret_T1  \\\n",
       "Date                                                                 \n",
       "2005-02-16   0.295820   0.111980   -0.024752  0.168478    0.943575   \n",
       "2005-02-17   0.205563   0.110439   -0.010152  0.051546    0.976270   \n",
       "2005-02-18   0.227057   0.102919   -0.010256  0.047120    0.975082   \n",
       "2005-02-21   0.233467   0.104258   -0.015544  0.079365    0.961305   \n",
       "2005-02-22   0.169630   0.104557    0.000000  0.143617    1.000000   \n",
       "...               ...        ...         ...       ...         ...   \n",
       "2023-06-30   0.394590   0.044682    0.000000  0.000000    1.000000   \n",
       "2023-07-03   0.387740   0.043768    0.020897  0.048802    1.032224   \n",
       "2023-07-04   0.390462   0.043734    0.016252  0.042634    1.022959   \n",
       "2023-07-05   0.386201   0.043440    0.001468  0.033487    1.002062   \n",
       "2023-07-06   0.414600   0.043695   -0.001011  0.019969    0.995319   \n",
       "\n",
       "            Returns_T2  Range_T2  RSI_Ret_T2  TARGET  \n",
       "Date                                                  \n",
       "2005-02-16    0.057591  0.093750    1.060351     0.0  \n",
       "2005-02-17   -0.024752  0.168478    0.943575     0.0  \n",
       "2005-02-18   -0.010152  0.051546    0.976270     1.0  \n",
       "2005-02-21   -0.010256  0.047120    0.975082     0.0  \n",
       "2005-02-22   -0.015544  0.079365    0.961305     0.0  \n",
       "...                ...       ...         ...     ...  \n",
       "2023-06-30    0.020249  0.033458    1.031909     0.0  \n",
       "2023-07-03    0.000000  0.000000    1.000000     0.0  \n",
       "2023-07-04    0.020897  0.048802    1.032224     0.0  \n",
       "2023-07-05    0.016252  0.042634    1.022959     1.0  \n",
       "2023-07-06    0.001468  0.033487    1.002062     0.0  \n",
       "\n",
       "[4538 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Feature Selection\n",
    "df_tts = df_tts.copy()\n",
    "if findFeature == False:\n",
    "    df_tts = df_tts[features]\n",
    "df_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (3630, 14)\n",
      "Shape of y_train:  (3630,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Params >> ne: 200, lr: 0.01 md: 8 gm: 20\n"
     ]
    }
   ],
   "source": [
    "# Perform Train Test Split\n",
    "# Split into Learning (X) and Target (y) Data\n",
    "X = df_tts.iloc[:, : -1]\n",
    "y = df_tts.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "\n",
    "# Select type of model to optimize for\n",
    "is_binary = True\n",
    "is_optimise_for_precision = True\n",
    "# Determine Objective and Eval Metrics\n",
    "if is_binary:\n",
    "    objective = \"binary:logistic\"\n",
    "    eval_metric = \"logloss\"\n",
    "    eval_metric_list = [\"error\", \"logloss\", eval_metric]\n",
    "else:\n",
    "    objective = \"multi:softmax\"\n",
    "    eval_metric = \"mlogloss\"\n",
    "    eval_metric_list = [\"merror\", \"mlogloss\", eval_metric]\n",
    "# Refine Eval Metric\n",
    "if is_binary and is_optimise_for_precision:\n",
    "    eval_metric = \"aucpr\"\n",
    "    scoring = \"precision\"\n",
    "elif is_binary and not is_optimise_for_precision:\n",
    "    eval_metric = \"auc\"\n",
    "    scoring = \"f1\"\n",
    "else:\n",
    "    scoring = \"accuracy\"\n",
    "# Build First Classifier Model 0\n",
    "classifier_0 = XGBClassifier(\n",
    "    objective=objective,\n",
    "    booster=\"gbtree\",\n",
    "    eval_metric=eval_metric,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=1,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "# Provide Gris for Hyperparams\n",
    "param_grid = {\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.5, 1, 1.5, 2, 3, 6, 12, 20],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 8, 12],\n",
    "    \"n_estimators\": [25, 50, 65, 80, 100, 115, 200]\n",
    "}\n",
    "grid_search = RandomizedSearchCV(estimator=classifier_0, param_distributions=param_grid, scoring=scoring)\n",
    "\n",
    "# Perform Random Search for Best Hyper params\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "hyperparams = best_model.best_params_\n",
    "ne = hyperparams[\"n_estimators\"]\n",
    "lr = hyperparams[\"learning_rate\"]\n",
    "md = hyperparams[\"max_depth\"]\n",
    "gm = hyperparams[\"gamma\"]\n",
    "print(\"Recommended Params >>\", f\"ne: {ne},\", f\"lr: {lr}\", f\"md: {md}\", f\"gm: {gm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# Build Classification Model 1\n",
    "classifier_1 = XGBClassifier(\n",
    "    objective=objective,\n",
    "    booster=\"gbtree\",\n",
    "    eval_metric=eval_metric,\n",
    "    n_estimators=ne,\n",
    "    learning_rate=lr,\n",
    "    max_depth=md,\n",
    "    gamma=gm,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=1,\n",
    "    use_label_encoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "eval_set = [(X_train, y_train)]\n",
    "classifier_1.set_params(eval_metric=eval_metric_list)  # Example metric: 'error'\n",
    "\n",
    "classifier_1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    #eval_metric=eval_metric_list,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Preds: \n",
      " [0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6476584022038567"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions for training data\n",
    "train_yhat = classifier_1.predict(X_train)\n",
    "print(\"Training Preds: \\n\", train_yhat[:5])\n",
    "accuracy_train = accuracy_score(y_train, train_yhat)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns</th>\n",
       "      <th>Range</th>\n",
       "      <th>RSI</th>\n",
       "      <th>RSI_Ret</th>\n",
       "      <th>MA_12</th>\n",
       "      <th>MA_21</th>\n",
       "      <th>Roll_Rets</th>\n",
       "      <th>Avg_Range</th>\n",
       "      <th>Returns_T1</th>\n",
       "      <th>Range_T1</th>\n",
       "      <th>RSI_Ret_T1</th>\n",
       "      <th>Returns_T2</th>\n",
       "      <th>Range_T2</th>\n",
       "      <th>RSI_Ret_T2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>-0.014778</td>\n",
       "      <td>0.045487</td>\n",
       "      <td>46.138648</td>\n",
       "      <td>0.974104</td>\n",
       "      <td>72.473280</td>\n",
       "      <td>63.755786</td>\n",
       "      <td>-0.074702</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.037562</td>\n",
       "      <td>1.016157</td>\n",
       "      <td>-0.030949</td>\n",
       "      <td>0.080576</td>\n",
       "      <td>0.950177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-17</th>\n",
       "      <td>-0.046296</td>\n",
       "      <td>0.069536</td>\n",
       "      <td>59.892852</td>\n",
       "      <td>0.862371</td>\n",
       "      <td>15.315273</td>\n",
       "      <td>14.581277</td>\n",
       "      <td>0.352338</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>-0.044248</td>\n",
       "      <td>0.050315</td>\n",
       "      <td>0.851805</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>53.727918</td>\n",
       "      <td>1.023720</td>\n",
       "      <td>665.816676</td>\n",
       "      <td>656.857149</td>\n",
       "      <td>0.099599</td>\n",
       "      <td>0.044244</td>\n",
       "      <td>-0.022082</td>\n",
       "      <td>0.033238</td>\n",
       "      <td>0.915577</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.023458</td>\n",
       "      <td>1.019262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-25</th>\n",
       "      <td>-0.035649</td>\n",
       "      <td>0.042065</td>\n",
       "      <td>58.271305</td>\n",
       "      <td>0.911121</td>\n",
       "      <td>217.074238</td>\n",
       "      <td>202.310114</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.046456</td>\n",
       "      <td>-0.023503</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>0.938843</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.036722</td>\n",
       "      <td>1.019255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>-0.046599</td>\n",
       "      <td>0.065134</td>\n",
       "      <td>58.085002</td>\n",
       "      <td>0.903556</td>\n",
       "      <td>828.835342</td>\n",
       "      <td>753.013062</td>\n",
       "      <td>0.355486</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.104415</td>\n",
       "      <td>1.032204</td>\n",
       "      <td>-0.049959</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.893051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20</th>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.035941</td>\n",
       "      <td>37.125447</td>\n",
       "      <td>1.005704</td>\n",
       "      <td>490.000003</td>\n",
       "      <td>494.264291</td>\n",
       "      <td>-0.104323</td>\n",
       "      <td>0.046072</td>\n",
       "      <td>-0.008878</td>\n",
       "      <td>0.022812</td>\n",
       "      <td>0.962235</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>0.045986</td>\n",
       "      <td>0.926684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-29</th>\n",
       "      <td>-0.009925</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>58.816536</td>\n",
       "      <td>0.985194</td>\n",
       "      <td>18.070457</td>\n",
       "      <td>15.994662</td>\n",
       "      <td>0.276649</td>\n",
       "      <td>0.102662</td>\n",
       "      <td>-0.042755</td>\n",
       "      <td>0.187179</td>\n",
       "      <td>0.937202</td>\n",
       "      <td>0.102094</td>\n",
       "      <td>0.166205</td>\n",
       "      <td>1.097440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>0.049731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.692412</td>\n",
       "      <td>1.014942</td>\n",
       "      <td>136.273084</td>\n",
       "      <td>114.986457</td>\n",
       "      <td>0.862456</td>\n",
       "      <td>0.058611</td>\n",
       "      <td>0.049884</td>\n",
       "      <td>0.045364</td>\n",
       "      <td>1.017161</td>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>1.019716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-10</th>\n",
       "      <td>0.049829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.163432</td>\n",
       "      <td>1.056566</td>\n",
       "      <td>62.404888</td>\n",
       "      <td>61.397810</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.048051</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.067897</td>\n",
       "      <td>0.049624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-07-31</th>\n",
       "      <td>0.052696</td>\n",
       "      <td>0.081761</td>\n",
       "      <td>42.833752</td>\n",
       "      <td>1.145882</td>\n",
       "      <td>40.541883</td>\n",
       "      <td>41.534380</td>\n",
       "      <td>-0.274516</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>-0.045614</td>\n",
       "      <td>0.038319</td>\n",
       "      <td>0.919662</td>\n",
       "      <td>-0.023973</td>\n",
       "      <td>0.069343</td>\n",
       "      <td>0.956322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Returns     Range        RSI   RSI_Ret       MA_12       MA_21  \\\n",
       "Date                                                                          \n",
       "2020-04-29 -0.014778  0.045487  46.138648  0.974104   72.473280   63.755786   \n",
       "2012-09-17 -0.046296  0.069536  59.892852  0.862371   15.315273   14.581277   \n",
       "2023-05-04  0.006682  0.019172  53.727918  1.023720  665.816676  656.857149   \n",
       "2021-03-25 -0.035649  0.042065  58.271305  0.911121  217.074238  202.310114   \n",
       "2021-12-01 -0.046599  0.065134  58.085002  0.903556  828.835342  753.013062   \n",
       "...              ...       ...        ...       ...         ...         ...   \n",
       "2023-01-20  0.000738  0.035941  37.125447  1.005704  490.000003  494.264291   \n",
       "2006-12-29 -0.009925  0.076923  58.816536  0.985194   18.070457   15.994662   \n",
       "2017-08-31  0.049731  0.000000  89.692412  1.014942  136.273084  114.986457   \n",
       "2020-06-10  0.049829  0.000000  71.163432  1.056566   62.404888   61.397810   \n",
       "2008-07-31  0.052696  0.081761  42.833752  1.145882   40.541883   41.534380   \n",
       "\n",
       "            Roll_Rets  Avg_Range  Returns_T1  Range_T1  RSI_Ret_T1  \\\n",
       "Date                                                                 \n",
       "2020-04-29  -0.074702   0.055251    0.008517  0.037562    1.016157   \n",
       "2012-09-17   0.352338   0.056769   -0.044248  0.050315    0.851805   \n",
       "2023-05-04   0.099599   0.044244   -0.022082  0.033238    0.915577   \n",
       "2021-03-25   0.190900   0.046456   -0.023503  0.046832    0.938843   \n",
       "2021-12-01   0.355486   0.060885    0.025639  0.104415    1.032204   \n",
       "...               ...        ...         ...       ...         ...   \n",
       "2023-01-20  -0.104323   0.046072   -0.008878  0.022812    0.962235   \n",
       "2006-12-29   0.276649   0.102662   -0.042755  0.187179    0.937202   \n",
       "2017-08-31   0.862456   0.058611    0.049884  0.045364    1.017161   \n",
       "2020-06-10   0.104723   0.048051    0.049427  0.000000    1.067897   \n",
       "2008-07-31  -0.274516   0.060032   -0.045614  0.038319    0.919662   \n",
       "\n",
       "            Returns_T2  Range_T2  RSI_Ret_T2  \n",
       "Date                                          \n",
       "2020-04-29   -0.030949  0.080576    0.950177  \n",
       "2012-09-17    0.002959  0.020833    1.002472  \n",
       "2023-05-04    0.006425  0.023458    1.019262  \n",
       "2021-03-25    0.015308  0.036722    1.019255  \n",
       "2021-12-01   -0.049959  0.026822    0.893051  \n",
       "...                ...       ...         ...  \n",
       "2023-01-20   -0.017547  0.045986    0.926684  \n",
       "2006-12-29    0.102094  0.166205    1.097440  \n",
       "2017-08-31    0.049930  0.065934    1.019716  \n",
       "2020-06-10    0.049624  0.000000    1.083673  \n",
       "2008-07-31   -0.023973  0.069343    0.956322  \n",
       "\n",
       "[3630 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set K-Fold Cross Validation Levels\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/Users/vipin/opt/anaconda3/envs/my_own/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "train_results = cross_val_score(classifier_1, X_train, y_train, scoring=scoring, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy K-Fold:  0.62\n",
      "Std Deviation K-Fold:  0.04\n",
      "Precision Score 0:  0.632\n",
      "Precision Score 1:  0.704\n",
      "\n",
      "Just for reference. Right now, we are only focussed on getting some initial features.\n",
      "If the results look too good to be true, they probably are.\n"
     ]
    }
   ],
   "source": [
    "# Brief Review of Training Results\n",
    "print(\"Average Accuracy K-Fold: \", round(train_results.mean(), 2))\n",
    "print(\"Std Deviation K-Fold: \", round(train_results.std(), 2))\n",
    "print(\"Precision Score 0: \", round(precision_score(y_train, train_yhat, average=None)[0], 3))\n",
    "print(\"Precision Score 1: \", round(precision_score(y_train, train_yhat, average=None)[1], 3))\n",
    "print(\"\")\n",
    "print(\"Just for reference. Right now, we are only focussed on getting some initial features.\")\n",
    "print(\"If the results look too good to be true, they probably are.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=[&#x27;error&#x27;, &#x27;logloss&#x27;, &#x27;logloss&#x27;], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=['error', 'logloss', 'logloss'], feature_types=None,\n",
       "              gamma=20, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_1.fit(\n",
    "    X,\n",
    "    y,\n",
    "    #eval_metric=eval_metric_list,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Feature Importances\n",
    "fig = plt.figure()\n",
    "importance_labels = X.columns\n",
    "importance_features = classifier_1.feature_importances_\n",
    "plt.bar(importance_labels, importance_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Features\n",
    "mean_feature_importance = importance_features.mean()\n",
    "i = 0\n",
    "recommended_feature_labels = []\n",
    "recommended_feature_score = []\n",
    "for fi in importance_features:\n",
    "    if fi > mean_feature_importance:\n",
    "        recommended_feature_labels.append(importance_labels[i])\n",
    "        recommended_feature_score.append(fi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Returns',\n",
       " 'Range',\n",
       " 'RSI',\n",
       " 'RSI_Ret',\n",
       " 'MA_21',\n",
       " 'Roll_Rets',\n",
       " 'Avg_Range',\n",
       " 'Returns_T1',\n",
       " 'Range_T1',\n",
       " 'Returns_T2',\n",
       " 'Range_T2']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONf4Fw76cQlH82pdR3h9Fa",
   "mount_file_id": "182alF94XmFPfm3NMnYKs4Tu9b-3DTW7y",
   "name": "Facebook Prophet + XGBoost Challenge Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
